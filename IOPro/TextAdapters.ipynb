{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Requirements](#Requirements)\n",
    "* [Getting started](#Getting-started)\n",
    "\t* [Installing license](#Installing-license)\n",
    "* [Text adapter](#Text-adapter)\n",
    "\t* [Gzip Support](#Gzip-Support)\n",
    "\t* [Indexing CSV Data](#Indexing-CSV-Data)\n",
    "\t* [Regular Expressions](#Regular-Expressions)\n",
    "\t* [`iopro.loadtext()` versus `iopro.genfromtxt()`](#iopro.loadtext%28%29-versus-iopro.genfromtxt%28%29)\n",
    "\t* [S3 Support](#S3-Support)\n",
    "* [JSON Support](#JSON-Support)\n",
    "\t* [Massaging data in the adapter](#Massaging-data-in-the-adapter)\n",
    "\t\t* [Combining regular expressions and typecastings](#Combining-regular-expressions-and-typecastings)\n",
    "\t* [Numba Integration](#Numba-Integration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python 2.7, or 3.4+\n",
    "- NumPy 1.10+\n",
    "\n",
    "Python modules (optional):\n",
    "\n",
    "- boto (for S3 support)\n",
    "- Pandas (to use DataFrames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOPro loads NumPy arrays (and Pandas DataFrames) directly from files,\n",
    "SQL databases, and NoSQL stores, without creating millions of temporary,\n",
    "intermediate Python objects, or requiring expensive array resizing\n",
    "operations. It provides a drop-in replacement for the NumPy functions\n",
    "loadtxt() and genfromtxt(), but drastically improves performance and\n",
    "reduces the memory overhead.\n",
    "\n",
    "IOPro is included with [Anaconda Workgroup and Anaconda Enterprise\n",
    "subscriptions](https://www.continuum.io/content/anaconda-subscriptions).\n",
    "\n",
    "To start a 30-day free trial just download and install the IOPro\n",
    "package.\n",
    "\n",
    "If you already have [Anaconda](http://continuum.io/downloads.html) (free\n",
    "Python distribution) installed:\n",
    "\n",
    "    conda update conda\n",
    "    conda install iopro\n",
    "\n",
    "If you do not have Anaconda installed, you can download it\n",
    "[here](http://continuum.io/downloads.html).\n",
    "\n",
    "IOPro can also be installed into your own (non-Anaconda) Python\n",
    "environment. For more information about IOPro please contact\n",
    "[<sales@continuum.io>](mailto:sales@continuum.io)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing license"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have obtained a license for long-term use of IOPro (and other Continuum products), you need to copy the license file to your `.continuum` directory under your home directory.  Generally in organizations, systems/IT will handle this.  For example, on my computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!jq \"\" ~/.continuum/license_bundle*.txt | sed 's/\"sig\": .*/\"sig\": \"XXXXXX\"/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, let's create a sample CSV file to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import random, randint, shuffle\n",
    "import string\n",
    "\n",
    "NUMROWS = 10\n",
    "with open('data/table.csv','w') as data:\n",
    "    # Header\n",
    "    for n in range(1,5):\n",
    "        print(\"f%d\" % n, end=\",\", file=data)\n",
    "    print(\"comment\", file=data)\n",
    "\n",
    "    # Body\n",
    "    letters = list(string.ascii_letters)\n",
    "    for n in range(NUMROWS):\n",
    "        shuffle(letters)\n",
    "        s = \"\".join(letters[:randint(5,20)])\n",
    "        vals = (n, randint(1000,2000), random(), random()*100, s)\n",
    "        print(\"%d,%d,%f,%f,%s\" % vals, file=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in the local CSV file created here.  Obviously, for a small file like this that easily fits in memory, the `csv` or `pandas` modules might be more than sufficient.  We want to show the interfaces and capabilities that will apply to much larger data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import iopro\n",
    "adapter = iopro.text_adapter('data/table.csv', parser='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adapter.get_field_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the data types for values in the columns of the csv file\n",
    "being read though here we will instead rely upon the ability of IOPro's\n",
    "TextAdapter to auto-discover the data types used.\n",
    "\n",
    "We ask IOPro's TextAdapter to parse text and return records in NumPy\n",
    "arrays from selected portions of the csv file using slicing notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the inferred datatypes\n",
    "array = adapter[:]\n",
    "array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define field dtypes (example: set field 0 to a 16-bit unsigned int and field 3 to a 32-bit float):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# massage the datatypes\n",
    "adapter.set_field_types({0: 'u2', 3:'f4'})\n",
    "array = adapter[:]\n",
    "array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the first five records\n",
    "array = adapter[0:5]\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read last five records\n",
    "array = adapter[-5:]\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read every other record\n",
    "array = adapter[::2]\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read first and second, third fields only\n",
    "array = adapter[[0,1,2]][:]\n",
    "list(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read fields named 'f2' and 'comment' only\n",
    "array = adapter[['f2','comment']][:]\n",
    "list(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gzip Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOPro can decompress gzip data on the fly, simply by indicating a `compression` keyword argument.\n",
    "\n",
    "```python\n",
    "adapter = iopro.text_adapter('data.gz', parser='csv', compression='gzip')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as being able to store and work with your compressed data without having to decompress first, you also do not need to sacrifice any performance in doing so. For example, with a test 419 MB CSV file of numerical data, and a 105 MB file of the same data compressed with gzip, the following are run times for loading the entire contents of each file into a NumPy array:\n",
    "\n",
    " - uncompressed: 13.38 sec\n",
    " - gzip compressed: 14.54 sec\n",
    "\n",
    "The compressed file takes slightly longer, but consider having to uncompress the file to disk before loading with IOPro:\n",
    "\n",
    " - uncompressed: 13.38 sec\n",
    " - gzip compressed: 14.54 sec\n",
    " - gzip compressed (decompress to disk, then load): 21.56 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing CSV Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most useful features of IOPro is the ability to index data to allow for fast random lookup.\n",
    "\n",
    "For example, to retrieve the last record of the compressed 109 MB dataset we used above:\n",
    "\n",
    "```\n",
    ">>> adapter = iopro.text_adapter('data.gz', parser='csv', compression='gzip')\n",
    ">>> array = adapter[-1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the last record into a NumPy array takes 14.82 sec. This is about the same as the time to read the entire record, because the entire dataset has to be parsed to get to the last record.\n",
    "\n",
    "To make seeking faster, we can build an index:\n",
    "\n",
    "```python\n",
    "adapter.create_index('index_file')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above method creates an index in memory and saves it to disk, taking 9.48 sec. Now when seeking to and reading the last record again, it takes a mere 0.02 sec.\n",
    "\n",
    "Reloading the index only takes 0.18 sec. Build an index once, and get near instant random access to your data forever:\n",
    "\n",
    "```python\n",
    "adapter = iopro.text_adapter('data.gz', parser='csv', \n",
    "                             compression='gzip', index_name='index_file')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with our more moderate sized example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adapter = iopro.text_adapter('data/exoplanets.csv.gz', parser='csv', compression='gzip')\n",
    "print(len(adapter[:]), \"rows\")\n",
    "print(', '.join(adapter.field_names[:3]), \n",
    "      \"...%d more...\" % (adapter.field_count-6), \n",
    "      ', '.join(adapter.field_names[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adapter.field_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time row=adapter[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time adapter.create_index('data/exoplanets.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time row=adapter[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time row=adapter[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_adapter = iopro.text_adapter('data/exoplanets.csv.gz', parser='csv', \n",
    "                                 compression='gzip', index_name='data/exoplanets.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time row=new_adapter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Some people, when confronted with a problem, think \n",
    "“I know, I'll use regular expressions.”   Now they have two problems. —Jamie Zawinski\n",
    "\n",
    "IOPro supports using regular expressions to help parse messy data. Take for example the following snippet of actual NASDAQ stock data found on the Internet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file data/stocks.csv\n",
    "Name,Symbol,Exchange,Range\n",
    "Apple,AAPL,NasdaqNM,363.32 - 705.07\n",
    "Google,GOOG,NasdaqNM,523.20 - 774.38\n",
    "Microsoft,MSFT,NasdaqNM,24.30 - 32.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three fields are easy enough: name, symbol, and exchange. The fourth field presents a bit of a problem. Let's try IOPro's regular expression based parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex_string = '([A-Za-z]+),([A-Z]{1,4}),([A-Za-z]+),'\\\n",
    "               '(\\d+.\\.\\d{2})\\s*\\-\\s*(\\d+.\\.\\d{2})'\n",
    "adapter = iopro.text_adapter('data/stocks.csv', parser='regex', \n",
    "                             regex_string=regex_string)\n",
    "\n",
    "# Notice that header does not now match the regex\n",
    "print(adapter.field_names)\n",
    "# We can massage the headers to reflect our match pattern\n",
    "adapter.field_names = adapter.field_names[0].split(',')[:3] + [\"Low\",\"High\"]\n",
    "adapter[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions are compact and often difficult to read, but they are also very powerful. By using the above regular expression with the grouping operators '(' and ')', we can define exactly how each record should be parsed into fields. Let's break it down into individual fields:\n",
    "\n",
    " * `([A-Za-z]+)` defines the first field (stock name) in our output array,\n",
    " * `([A-Z]{1-4})` defines the second (stock symbol),\n",
    " * `([A-Za-z]+)` defines the third (exchange name),\n",
    " * `(\\d+.\\.\\d{2})` defines the fourth field (low price)\n",
    " * `\\s*\\-\\s*` is skipped because it is not part of a group\n",
    " * `(\\d+.\\.\\d{2})` defines the fifth field (high price)\n",
    "\n",
    "The output array contains five fields: three string fields and two float fields. Exactly what we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `iopro.loadtext()` versus `iopro.genfromtxt()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within IOPro there are two closely related functions.  `loadtext()`, that we have been looking at, Makes a more optimistic assumption that your data is well-formatted.  `genfromtxt()` has a number of arguments for handling messier data, and special behaviors for dealing with missing data.\n",
    "\n",
    "`loadtext()` is already highly configurable for dealing with data under many CSV and other delimitered formats.  `genfromtxt()` contains a superset of these arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(iopro.loadtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(iopro.genfromtxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOPro can parse CSV data stored in Amazon's S3 cloud storage service. In order to access S3 files, you need to specify some credentials along with the resource you are accessing.\n",
    "\n",
    "The first two parameters are your AWS access key and secret key, followed by the S3 bucket name and key name. The S3 CSV data is downloaded in 128K chunks and parsed directly from memory, bypassing the need to save the entire S3 data set to local disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Health Insurance Marketplace data\n",
    "import iopro\n",
    "import urllib.request\n",
    "url = 'http://s3.amazonaws.com/product-training/'\n",
    "xml = urllib.request.urlopen(url).read()\n",
    "#print(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bs4, re\n",
    "r = re.compile(r'^(\\s*)', re.MULTILINE)\n",
    "def display(bs, encoding=None, formatter=\"minimal\", indent=4):\n",
    "    print(r.sub(r'\\1' * indent, bs.prettify(encoding, formatter)))\n",
    "\n",
    "display(bs4.BeautifulSoup(xml, \"xml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_name = \"class1\"\n",
    "aws_access_key = \"AKIAINKGGVI5HNOKN5MQ\"\n",
    "aws_secret_key = \"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\"\n",
    "bucket = 'product-training'\n",
    "key_name = 'BusinessRules.csv' # 21k lines, 8MB\n",
    "# key_name = 'PlanAttributes.csv' # 77k lines, 95MB\n",
    "# key_name = 'Rate.csv.gzip' # 13M lines, 2GB uncompressed, 110MB compressed\n",
    "adapter = iopro.s3_text_adapter(aws_access_key, aws_secret_key, bucket, key_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Don't try this with the really large datasets, works with the default one\n",
    "df = adapter.to_dataframe()\n",
    "df.iloc[:6,:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOPro can also build an index for S3 data just as with disk based CSV data, and use the index for fast random access lookup. If an index file is created with IOPro and stored with the S3 dataset in the cloud, IOPro can use this remote index to download and parse just the subset of records requested. This allows you to generate an index file once and share it on the cloud along with the data set, and does not require others to download the entire index file to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text data in JSON format can be parsed by specifying 'json' for the parser argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file data/one.json\n",
    "{\"id\":123, \"name\":\"xxx\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Single JSON object\n",
    "adapter = iopro.text_adapter('data/one.json', parser='json')\n",
    "adapter[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, each JSON object at the root level is interpreted as a single NumPy record. Each JSON object can be part of an array, or separated by a newline. Examples of valid JSON documents that can be parsed by IOPro, with the NumPy array result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file data/two.json\n",
    "[{\"id\":123, \"name\":\"xxx\"}, {\"id\":456, \"name\":\"yyy\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Array of two JSON objects\n",
    "iopro.text_adapter('data/two.json', parser='json')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file data/three.json\n",
    "{\"id\":123, \"name\":\"xxx\"}\n",
    "{\"id\":456, \"name\":\"yyy\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Two JSON objects separated by newline\n",
    "iopro.text_adapter('data/three.json', parser='json')[:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future versions of IOPro will have support for selecting specific JSON fields, using a query language similar to XPath for XML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massaging data in the adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A custom function can be used to modify values as they are read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import iopro, io, math\n",
    "stream = io.StringIO('3,abc,3.3\\n7,xxx,9.9\\n4,,')\n",
    "adapter = iopro.text_adapter(stream, parser='csv', field_names=False)\n",
    "\n",
    "# Override default converter for first field\n",
    "adapter.set_converter(0, lambda x: math.factorial(int(x)))\n",
    "\n",
    "adapter[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also for data types and set fill values for missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply data types to columns\n",
    "stream = io.StringIO('3,abc,3.3\\n7,xxx,9.9\\n4,,')\n",
    "adapter = iopro.text_adapter(stream, parser='csv', field_names=False)\n",
    "adapter.set_field_types({1:'S3', 2:'f4'})\n",
    "adapter[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set fill value for missing values in each field\n",
    "adapter.set_fill_values({1:'ZZZ', 2:999.999})\n",
    "adapter[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining regular expressions and typecastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file data/transactions.csv\n",
    "$2.56, 50%, September 20 1978\n",
    "$1.23, 23%, April 5 1981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import iopro\n",
    "\n",
    "regex_string = '\\$(\\d)\\.(\\d{2}),\\s*([0-9]+)\\%,\\s*([A-Za-z]+)'\n",
    "adapter = iopro.text_adapter('data/transactions.csv', \n",
    "                             parser='regex', \n",
    "                             regex_string=regex_string, \n",
    "                             field_names=False, \n",
    "                             infer_types=False)\n",
    "\n",
    "# Set dtype of fields and their names\n",
    "adapter.set_field_types({0:'i2', 1:'u2', 2:'f4', 3:'S10'})\n",
    "adapter.set_field_names(['dollars', 'cents', 'percentage', 'month'])\n",
    "adapter[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOPro comes with experimental integration with NumbaPro, the amazing NumPy aware Python compiler also available in Anaconda. Previously when parsing messy csv data, you had to use either a very slow custom Python converter function to convert the string data to the target data type, or use a complex regular expression to define the fields in each record string. Using the regular expression feature of IOPro will certainly still be a useful and valid option for certain types of data, but it would be nice if custom Python converter functions weren't so slow as to be almost unusable. Numba solves this problem by compiling your converter functions on the fly without any action on your part. Simply set the converter function with a call to set_converter_function() as before, and IOPro + NumbaPro will handle the rest. To illustrate, I'll show a trivial example using the sdss data set again. Take the following converter function which converts the input string to a floating point value and rounds to the nearest integer, returning the integer value:\n",
    "\n",
    "```\n",
    ">>> def convert_value(input_str):\n",
    "...     float_value = float(input_str)\n",
    "...     return int(round(float_value))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use it to convert field 1 from the sdss dataset to an integer. By calling the set_converter method with the use_numba parameter set to either True or False (the default is True), we can test the converter function being called as both interpreted Python and as Numba compiled llvm bytecode. In this case, compiling the converter function with NumbaPro gives us a 5x improvement in run time performance. To put that in perspective, the Numba compiled converter function takes about the same time as converting field 1 to a float value using IOPro's built in C compiled float converter function. That isn't quite an \"apples to apples\" comparison, but it does show that NumbaPro enables user defined python converter functions to achieve speeds in the same league as compiled C code."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [iqt]",
   "language": "python",
   "name": "Python [iqt]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
