{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Learning Objectives:](#Learning-Objectives:)\n",
    "* [Excel](#Excel)\n",
    "\t* [Pandas categoricals](#Pandas-categoricals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completion of this module, learners should be able to:\n",
    "\n",
    "* Access data stored in Excel spreadsheets\n",
    "* Identify and normalize redundant data in tabular formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several 3rd party Python modules for working with Microsoft Excel spreadsheets.  A list of them is collected at:\n",
    "\n",
    "* [Working with Excel Files in Python](http://www.python-excel.org/)\n",
    "\n",
    "I've used [openpyxl](https://openpyxl.readthedocs.org/en/latest/) successfully in some projects.\n",
    "\n",
    "However, within the Scientific Python toolstack, the most common way of accessing the Excel format is the [Pandas](http://pandas.pydata.org/) framework. This is heavier weight than other options if all you wanted to do was read Excel, but in a scientific context, you already need most of the requirements (NumPy, etc), and you probably want to be using Pandas for numerous other purposes anyway.\n",
    "\n",
    "Pandas relies internally uses `xlrd` to read Excel files, but provides a higher-level wrapper. You probably need to run:\n",
    "\n",
    "```bash\n",
    "conda install xlrd\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the below commands to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's import the packages we will use in this Notebook\n",
    "import pandas as pd\n",
    "\n",
    "# A large(-ish) data set contained in an Excel spreadsheet\n",
    "# 24 MiB file, 300k rows of largely categorical data\n",
    "nyc_harbor_file = \"data/nyc_harbor_wq_2006-2014.xlsx\"\n",
    "harbor_data = pd.read_excel(nyc_harbor_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "harbor_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "harbor_data.UNIT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations = harbor_data.STATION.unique()\n",
    "station_ids = map(str, stations)\n",
    "print(sorted(station_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The first row in which STATION 'GB1N' occurs\n",
    "harbor_data[harbor_data.STATION == 'GB1N'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "harbor_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(harbor_data.DATE[:5])\n",
    "print()\n",
    "print(harbor_data.RESULT[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "harbor_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "harbor_data[['STATION','DATE','RESULT']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "harbor_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station_not_name = harbor_data[harbor_data.STATION != harbor_data.STATION_NAME]\n",
    "station_not_name[['STATION','STATION_NAME','DATE','PARAMETER_NAME']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas categoricals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related to the normalization, we might notice that our Pandas `DataFrame` itself is inefficient for the same reasons that normalization is desirable.  A large number of copies of the same strings are stored within the same column `Series` objects.  Moreover, in many cases what is stored are strings which need to be stored as Python objects, and processed much more slowly and indirectly than with basic numeric types that leverage their underlying `numpy` arrays.  We can improve this quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Let's take a look at a relatively expensive query\n",
    "water_depths = harbor_data.groupby(harbor_data.STATION).DEPTH_WATERCOL_FT.mean()\n",
    "known_depths = water_depths[pd.notnull(water_depths)]\n",
    "known_depths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert STATION to a categorical\n",
    "harbor_data.STATION = harbor_data.STATION.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Run same operations on categoricalized DataFrame\n",
    "water_depths = harbor_data.groupby(harbor_data.STATION).DEPTH_WATERCOL_FT.mean()\n",
    "known_depths = water_depths[pd.notnull(water_depths)]\n",
    "known_depths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "water_depths = harbor_data.groupby(harbor_data.STATION).DEPTH_WATERCOL_FT.mean()\n",
    "known_depths = water_depths[pd.notnull(water_depths)]\n",
    "known_depths.sort()\n",
    "known_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what happened there? We can see that the data still *looks* the same on a cursory look.  But its storage strategy is much more efficient now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "harbor_data[['STATION', 'DEPTH_WATERCOL_FT']][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "harbor_data.STATION[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "harbor_data.STATION.cat.codes[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can check which columns are good candidates to make categorical\n",
    "harbor_data.dtypes[harbor_data.dtypes == object]"
   ]
  }
 ],
 "metadata": {
  "continuum": {
   "depends": [
    "pd_ex_nested"
   ],
   "requires": [
    "data/nyc_harbor_wq_2006-2014.xlsx"
   ],
   "tag": "pd_excel"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
