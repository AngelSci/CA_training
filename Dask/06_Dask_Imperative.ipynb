{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Anaconda\"](img/anaconda-logo.png)\n",
    "<br>\n",
    "*Copyright Continuum 2012-2016 All Rights Reserved.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask and Imperative Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **dask `do()` function** helps you to construct custom dask graphs using more typical coding styles than the explicit construction of a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Dask and Imperative Programming](#Dask-and-Imperative-Programming)\n",
    "* [Imperative Programming](#Imperative-Programming)\n",
    "\t* [Custom graphs with `do`](#Custom-graphs-with-do)\n",
    "\t* [A Familiar Example](#A-Familiar-Example)\n",
    "* [Exercise 1: Create a Graph](#Exercise-1:-Create-a-Graph)\n",
    "* [Exercise 2: Parallel Estimation of Pi](#Exercise-2:-Parallel-Estimation-of-Pi)\n",
    "* [Exercise 3: Small Tasks in Parallel](#Exercise-3:-Small-Tasks-in-Parallel)\n",
    "* [Exercise 4: GIL vs Multiprocessing](#Exercise-4:-GIL-vs-Multiprocessing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imperative Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many problems don't fit cleanly into `ndarray` or `DataFrame` abstractions.  How can we use dask to parallelize more custom workloads?\n",
    "\n",
    "We can always fall back to creating dictionaries manually:\n",
    "\n",
    "    dsk = {'load-1': (load, filename1), 'clean-1': (clean, 'load-1'), ...,\n",
    "           'load-2': (load, filename2), 'clean-2': (clean, 'load-2'), ...,\n",
    "           ...}\n",
    "    \n",
    "Manual dictionary creation has some drawbacks:\n",
    "\n",
    "* can be tedious\n",
    "* is prone to programmer error\n",
    "* feels foreign to many developers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom graphs with `do`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `do` function delays a function evaluation, producing a lazily evaluated result.  One wraps a function with a `do` call\n",
    "\n",
    "*  Before:  \n",
    "\n",
    "        result = f(a, b, c=10)\n",
    "*  After:  \n",
    "\n",
    "        result = do(f)(a, b, c=10)\n",
    "        \n",
    "The result of a call to `do(function)` is a lazy `Value` object that we can use in future `do` calls or eventually call `.compute()`\n",
    "\n",
    "    >>> result.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Familiar Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore this abstraction we revisit our examples from the [Foundations Notebook](Foundations.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "a = 1\n",
    "b = inc(a)\n",
    "\n",
    "x = 10\n",
    "y = inc(x)\n",
    "\n",
    "z = add(b, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally we parallelized this by constructing a dask graph explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsk = {'a': 1, \n",
    "       'b': (inc, 'a'),\n",
    "       \n",
    "       'x': 10,\n",
    "       'y': (inc, 'x'),\n",
    "       \n",
    "       'z': (add, 'b', 'y')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can also use the `do()` function to construct the dask graph with more traditional programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask import do\n",
    "\n",
    "a = 1\n",
    "b = do(inc)(a)\n",
    "\n",
    "x = 10\n",
    "y = do(inc)(x)\n",
    "\n",
    "z = do(add)(b, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These value objects build up the dask graph as they go.  These graphs are less interpretable but fine for normal execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z.dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z._visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Create a Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider our first exercise reading three CSV files with `pd.read_csv` and then measuring their total length.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.dask_prep import accounts_csvs  # Prep data if it doesn't exist\n",
    "accounts_csvs(3, 1000000, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "filenames = [os.path.join('tmp', 'accounts.%d.csv' % i) \n",
    "                for i in [0, 1, 2]]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "a = pd.read_csv(filenames[0])\n",
    "b = pd.read_csv(filenames[1])\n",
    "c = pd.read_csv(filenames[2])\n",
    "\n",
    "na = len(a)\n",
    "nb = len(b)\n",
    "nc = len(c)\n",
    "\n",
    "total = sum([na, nb, nc])\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first notebook we constructed a dask graph from this computation and then executed it in parallel using multiple processes to get a speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load solutions/Foundations-01.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask.multiprocessing import get\n",
    "%time  get(dsk, 'total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to recreate this graph again using the `do` function on the original Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = do(pd.read_csv)(filenames[0])\n",
    "#...\n",
    "\n",
    "#total = ...\n",
    "\n",
    "%time total.compute(get=get) # use multiprocessing get function in call to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load solutions/Imperative-01.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Parallel Estimation of Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/84/Pi_30K.gif\" align=\"right\" width=\"40%\">\n",
    "\n",
    "\n",
    "\n",
    "Below is a function that approximates $\\pi$ using a [Monte Carlo method](https://en.wikipedia.org/wiki/Monte_Carlo_method). It works by generating random points in a 1 x 1 square, and then counts those that are inside a quarter circle of radius one (as seen in the image to the right). Since the area of the full circle is $\\pi$, then this can be estimated by \n",
    "\n",
    "$$4 \\times \\frac{\\mathrm{points–in–circle}}{\\mathrm{total–points}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from random import random\n",
    "\n",
    "def is_inside_circle():\n",
    "    \"\"\"Generates a random x, y point, returns 1 if in circle, else returns 0.\"\"\"\n",
    "    x = random()\n",
    "    y = random()\n",
    "    if x**2 + y**2 <= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def estimate_pi(nsamples):\n",
    "    count = [is_inside_circle() for i in range(nsamples)]\n",
    "    return 4. * sum(count) / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimate_pi(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to use `dask.do()` to make a parallel version of `estimate_pi()` by using `do()` on the `is_inside_circle()` calls and anything else that needs to be delayed as a result.\n",
    "\n",
    "Test out your function as we did above on the serial version.  What does your function return?  How does this perform compared to the serial version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load solutions/Imperative-02.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Small Tasks in Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your parallel version probably runs significantly slower than the sequential version.  This is true even though there is a large amount of available parallelism.\n",
    "\n",
    "This is because each of our tasks is *very small*.  The dask schedulers add an overhead of around 1ms per task, making them good at *medium grained parallelism* where tasks take around 100ms or so.  When the task size gets to be much smaller than this then then the scheduler overhead dominates.\n",
    "\n",
    "This can be fixed by bundling up many calls to `is_inside_circle()` into a single task.  Make a new function that calls `is_inside_circle()` many times (and figure out how many is a good number) and then rewrite your parallel function to call this function instead.\n",
    "\n",
    "Do you get a speedup?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load solutions/Imperative-03.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: GIL vs Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, these computations are all happening in Python and so we are bound by the Global Interpreter Lock (GIL) when we use the default threaded scheduler.  \n",
    "\n",
    "Use the multiprocessing scheduler instead and see how your performance changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask.multiprocessing import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "*Copyright Continuum 2012-2016 All Rights Reserved.*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "continuum": {
   "depends": [
    "dask_foundations",
    "dask_pd"
   ],
   "requires": [
    "data/__init__.py",
    "data/solutions/*",
    "src/dask_prep.py",
    "data/solutions/Imperative-01.py",
    "data/solutions/Imperative-02.py",
    "data/solutions/Imperative-03.py"
   ],
   "tag": "dask_imperative"
  },
  "kernelspec": {
   "display_name": "Python [conda env:iqt]",
   "language": "python",
   "name": "conda-env-iqt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
