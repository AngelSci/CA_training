{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Anaconda\"](img/anaconda-logo.png)\n",
    "<br>\n",
    "*Copyright Continuum 2012-2016 All Rights Reserved.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask: Graph Foundations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/fail-case.gif\" width=40% align=\"right\">\n",
    "\n",
    "*Dask is a way to represent computations as dictionaries, and then analyze and execute them.*\n",
    "\n",
    "* Dask supports parallel computing.  Internally it executes graphs of tasks with data dependencies.  \n",
    "* In this section we talk about what these graphs look like and how to construct them.  \n",
    "* We finish with exercises manually building graphs that use basic Pandas functionality.  \n",
    "* This is straightforward but somewhat tedious.  We'll automate it in future sections.\n",
    "\n",
    "***You can safely skip this section if you don't care about how dask works internally.***\n",
    "\n",
    "**Related Documentation**\n",
    "\n",
    "*  [Dask graph specification](http://dask.pydata.org/en/latest/spec.html)\n",
    "*  [Discussion on custom graphs](http://dask.pydata.org/en/latest/custom-graphs.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Dask: Graph Foundations](#Dask:-Graph-Foundations)\n",
    "* [Normal Programming](#Normal-Programming)\n",
    "\t* [Make functions](#Make-functions)\n",
    "\t* [Call functions in code](#Call-functions-in-code)\n",
    "* [Computation as a data structure](#Computation-as-a-data-structure)\n",
    "* [Delayed Evaluation in Python](#Delayed-Evaluation-in-Python)\n",
    "\t* [Example 1: `eval()`](#Example-1:-eval%28%29)\n",
    "\t* [Example 2: `lambda`](#Example-2:-lambda)\n",
    "\t* [Example 3: `functools`](#Example-3:-functools)\n",
    "\t* [Dask delays evaluation](#Dask-delays-evaluation)\n",
    "* [Defining dask graphs](#Defining-dask-graphs)\n",
    "* [Executing dask graphs](#Executing-dask-graphs)\n",
    "* [Analyzing and Visualizing Graphs](#Analyzing-and-Visualizing-Graphs)\n",
    "* [Exercise 1: `read_csv`](#Exercise-1:-read_csv)\n",
    "\t* [Data prep](#Data-prep)\n",
    "\t* [File reads](#File-reads)\n",
    "\t* [Construct a dask graph](#Construct-a-dask-graph)\n",
    "\t* [Solution](#Solution)\n",
    "\t* [Execute your dask graph](#Execute-your-dask-graph)\n",
    "* [Exercise 2: Sum of amounts](#Exercise-2:-Sum-of-amounts)\n",
    "\t* [Solution](#Solution)\n",
    "* [Conclusion](#Conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally we write functions and then use those function in linear code.  \n",
    "\n",
    "The Python interpreter executes this code from the top down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call functions in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = inc(a)\n",
    "\n",
    "x = 10\n",
    "y = inc(x)\n",
    "\n",
    "z = add(b, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though some of this work could have happened in parallel, Python went ahead and executed one line after the other sequentially.\n",
    "\n",
    "If we want to execute code in parallel then we need to stop Python from taking control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation as a data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of writing normal code we store the stages of the computation above as a Python dictionary where each function call becomes a Python tuple.\n",
    "\n",
    "This is going to look a little strange but we'll have the entire computation stored in a Python data structure that we can manipulate with *other* Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsk = {'a': 1, \n",
    "       'b': (inc, 'a'),\n",
    "       \n",
    "       'x': 10,\n",
    "       'y': (inc, 'x'),\n",
    "       \n",
    "       'z': (add, 'b', 'y')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(dsk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call a dictionary that looks like this a *dask graph*.  ***A dask graph is just a dictionary.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delayed Evaluation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing Python functions as tuples containing function names and arguments may seem strange, but in reality you are already familiar with the style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: `eval()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sometimes we defer computations with strings\n",
    "x = 15\n",
    "y = 30\n",
    "z = \"x + y\"\n",
    "eval(z)\n",
    "\n",
    "# The variable 'z' stores a string that is a valid Python statement\n",
    "# We call eval to fully evaluate `z' and obtain the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: `lambda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sometimes we defer computations with a lambda\n",
    "\n",
    "x = 15\n",
    "y = 30\n",
    "z = lambda: x + y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# z delays the execution of x + y until we call z()\n",
    "# This is very similar to (add, 'x', 'y')\n",
    "z()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: `functools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sometimes we use functools.partial\n",
    "\n",
    "import functools\n",
    "z = functools.partial(add, x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask delays evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dask delays evaluation with tuples\n",
    "z = (add, x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining dask graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be fully explicit, here is the definition of a dask graph taken from the [dask documentation](http://dask.pydata.org/en/latest/spec.html)\n",
    "\n",
    "A **dask graph** is a dictionary mapping data-keys to values or tasks.\n",
    "\n",
    "```python\n",
    "{'x': 1,\n",
    " 'y': 2,\n",
    " 'z': (add, 'x', 'y'),\n",
    " 'w': (sum, ['x', 'y', 'z'])}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **key** can be any hashable value that is not a task.\n",
    "\n",
    "```python\n",
    "'x'\n",
    "('x', 2, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **task** is a tuple with a callable first element. Tasks represent atomic units of work meant to be run by a single worker.\n",
    "\n",
    "```python\n",
    "(add, 'x', 'y')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We represent a task as a `tuple` such that the *first element is a callable function* (like `add`), and the succeeding elements are *arguments* for that function.\n",
    "\n",
    "An **argument** to a task may be one of the following:\n",
    "\n",
    "1. Any key present in the dask like `'x'`\n",
    "2. Any other value like `1`, to be interpreted literally\n",
    "3. Other tasks like `(inc, 'x')`\n",
    "4. List of arguments, like `[1, 'x', (inc, 'x')]`\n",
    "\n",
    "So all of the following are valid tasks\n",
    "\n",
    "```python\n",
    "(add, 1, 2)\n",
    "(add, 'x', 2)\n",
    "(add, (inc, 'x'), 2)\n",
    "(sum, [1, 2])\n",
    "(sum, ['x', (inc, 'x')])\n",
    "(np.dot, np.array([...]), np.array([...]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing dask graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dask library contains functions to execute these dictionaries in parallel with multiple threads or multiple processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask.threaded import get\n",
    "get(dsk, 'z')  # Execute in multiple threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask.multiprocessing import get\n",
    "get(dsk, 'z')  # Execute in multiple processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as long as you're willing to write code in this funny way with dictionaries, dask will run your separate functions in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing and Visualizing Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our computation is just a dictionary we can write arbitrary functions to do a variety of useful analyses on these dictionaries.  A simple yet common operation is just to visualize the computation as a visual graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Requires that you have pydot and graphviz installed\n",
    "# !conda install graphviz pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you don't want to install graphviz, feel free to skip this cell!\n",
    "from dask.dot import dot_graph\n",
    "dot_graph(dsk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it\n",
    "----------\n",
    "\n",
    "The rest of this tutorial contains fancy ways to construct and execute dask graphs.  We won't make any more by hand after this notebook.  \n",
    "\n",
    "If you'd like to learn more, read the [dask graph spec](http://dask.pydata.org/en/latest/spec.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: `read_csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an exercise we'll parallelize some basic Pandas code by rewriting it as a dask graph.  \n",
    "\n",
    "* This will be a little tedious but should give us speed-ups right away.  \n",
    "* In future sections we'll learn how dask submodules like `dask.dataframe` automate this work for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three CSV files in your `data` directory.\n",
    "\n",
    "* We count how many rows are in all of these csv files total.\n",
    "* In normal Python we solve this problem in the following way..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.dask_prep import accounts_csvs  # Prep data if it doesn't exist\n",
    "accounts_csvs(3, 1000000, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "filenames = [os.path.join('tmp', 'accounts.%d.csv' % i) for i in [0, 1, 2]]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -lh tmp/accounts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_csv(filenames[0], nrows=5)  # a sample of the first file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "a = pd.read_csv(filenames[0])\n",
    "b = pd.read_csv(filenames[1])\n",
    "c = pd.read_csv(filenames[2])\n",
    "\n",
    "na = len(a)\n",
    "nb = len(b)\n",
    "nc = len(c)\n",
    "\n",
    "total = sum([na, nb, nc])\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a dask graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a dask graph/dictionary for this computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we turned code that looks like \n",
    "\n",
    "```python\n",
    "y = f(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "into dictionaries like \n",
    "\n",
    "```python\n",
    "{'y': (f, 'x')}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can transform the above calls to `pd.read_csv`, `len`, and `sum` into a dictionary of tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```python\n",
    "dsk = {'a': (pd.read_csv, filenames[0]),\n",
    "       'b': ...,\n",
    "       ...\n",
    "       'total': ...}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enter your solution here: should just be a dictionary!\n",
    "dsk = {  }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load solutions/Foundations-01.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute your dask graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We execute dask graphs with the `get` functions.  There is a get function for both multi-threading and multi-processing.  Get takes two arguments\n",
    "\n",
    "    get(dsk, output_key)\n",
    "\n",
    "Run the following cells and see how each get function performs.  Why is there a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask.threaded import get\n",
    "%time get(dsk, 'total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask.multiprocessing import get\n",
    "%time get(dsk, 'total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Sum of amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a slightly more complex example we'll compute the sum of the amounts column in each CSV file and then add up these sums to get the total amount over all CSV files.\n",
    "\n",
    "To make the graph construction slightly more challenging we'll use Python for loops rather than write out every entry by hand.\n",
    "\n",
    "In normal sequential code we might execute the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sums = list()\n",
    "for fn in filenames:\n",
    "    df = pd.read_csv(fn)\n",
    "    sums.append(df.amount.sum())\n",
    "total = sum(sums)\n",
    "total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the same computation as a dask graph.\n",
    "\n",
    "We suggest building and using a small function to compute the sum of the amount of a dataframe and using this function in your dask graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def amount_sum(df):\n",
    "    return df.amount.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```python\n",
    "dsk = dict()\n",
    "\n",
    "for fn in filenames:\n",
    "    dsk[...] = ...\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load solutions/Foundations-02.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get(dsk, 'total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've learned about how dask graph represent computations and how we can execute these computations with dask schedulers / get functions.  We've made a few of these dictionaries by hand.  It's straightforward but perhaps tiresome.\n",
    "\n",
    "In the next sections we'll play with systems that generate these dictionaries for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "*Copyright Continuum 2012-2016 All Rights Reserved.*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "continuum": {
   "depends": [
    "dask_pd"
   ],
   "requires": [
    "data/__init__.py",
    "data/solutions/*",
    "src/dask_prep.py",
    "img/fail-case.gif",
    "data/solutions/Foundations-02.py"
   ],
   "tag": "dask_foundations"
  },
  "kernelspec": {
   "display_name": "Python [conda env:iqt]",
   "language": "python",
   "name": "conda-env-iqt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
