{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/anaconda-logo.png' align='left' style=\"padding:10px\">\n",
    "<br>\n",
    "*Copyright Continuum 2012-2016 All Rights Reserved.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerate Signal Processing: FFT Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we demonstrate the use of **hardware optimized FFT** functions from *Accelerate* to **speedup convolution** for image processing.\n",
    "\n",
    "* We can use the `vectorize` decorator for higher-level annotation of numeric functions and get a great deal of GPU benefit.  \n",
    "* However, we also have the option of more explicitly controlling CUDA operations, as shown in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Accelerate Signal Processing: FFT Convolution](#Accelerate-Signal-Processing:-FFT-Convolution)\n",
    "\t* [Overview](#Overview)\n",
    "\t* [Set-up](#Set-up)\n",
    "\t* [Prepare data](#Prepare-data)\n",
    "* [Comparing implementations of a Convolution](#Comparing-implementations-of-a-Convolution)\n",
    "\t* [Numpy naive implementation](#Numpy-naive-implementation)\n",
    "\t* [Scipy Implementation](#Scipy-Implementation)\n",
    "\t* [Accelerate Implementation with MKL](#Accelerate-Implementation-with-MKL)\n",
    "\t* [Accelerate Implementation with GPU](#Accelerate-Implementation-with-GPU)\n",
    "\t* [Comparing all Implementations](#Comparing-all-Implementations)\n",
    "\t* [Using VML to intrinsics](#Using-VML-to-intrinsics)\n",
    "\t* [Script for convolution filter](#Script-for-convolution-filter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.misc import imresize\n",
    "import skimage.data\n",
    "from skimage.color import rgb2gray\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from numba import cuda, vectorize\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build 5x5 laplacian filter\n",
    "laplacian_pts = '''\n",
    "-4 -1 0 -1 -4\n",
    "-1  2 3  2 -1\n",
    " 0  3 4  3  0\n",
    "-1  2 3  2 -1\n",
    "-4 -1 0 -1 -4\n",
    "'''.split()\n",
    "\n",
    "laplacian = np.array(laplacian_pts, dtype=np.float32).reshape(5, 5)\n",
    "\n",
    "# Build Image\n",
    "image = rgb2gray(skimage.data.astronaut())\n",
    "image = imresize(image, 2.0).astype(np.float32)\n",
    "\n",
    "print(\"Image size: %s\" % (image.shape,))\n",
    "\n",
    "response = np.zeros_like(image)\n",
    "response[:5, :5] = laplacian\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(image, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(response[:5, :5], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing implementations of a Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herein, we'll demonstrate 4 different implementations and then profile and compare each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy naive implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def naive_fftconvolve(image):\n",
    "    freq_image = np.fft.rfft2(image)\n",
    "    freq_response = np.fft.rfft2(response)\n",
    "    return np.fft.irfft2(freq_image * freq_response).real\n",
    "\n",
    "cvimage_naive = naive_fftconvolve(image)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(cvimage_naive, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using scipy.signal.fftconvolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cvimage_cpu = fftconvolve(image, laplacian, mode='same')\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(cvimage_cpu, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelerate Implementation with MKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import accelerate.mkl.fftpack as mklfft\n",
    "\n",
    "def mkl_fftconvolve(image):\n",
    "    freq_image = mklfft.rfft2(image)\n",
    "    freq_response = mklfft.rfft2(response)\n",
    "    return mklfft.irfft2(freq_image * freq_response).real\n",
    "\n",
    "cvimage_mkl = mkl_fftconvolve(image)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(cvimage_mkl, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelerate Implementation with GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import accelerate.cuda.fft as cufft\n",
    "\n",
    "@vectorize(['complex64(complex64, complex64)'], target='cuda')\n",
    "def gpu_mult(a, b):\n",
    "    # a GPU ufunc to compute the elementwise product \n",
    "    return a * b\n",
    "\n",
    "\n",
    "def gpu_fftconvolve(image):\n",
    "    image_complex = image.astype(np.complex64)\n",
    "    response_complex = response.astype(np.complex64)\n",
    "\n",
    "    # explicit CPU->GPU memory transfer\n",
    "    d_image_complex = cuda.to_device(image_complex)\n",
    "    d_response_complex = cuda.to_device(response_complex)\n",
    "\n",
    "    # GPU forward FFT\n",
    "    cufft.fft_inplace(d_image_complex)\n",
    "    cufft.fft_inplace(d_response_complex)\n",
    "\n",
    "    # GPU ufunc\n",
    "    gpu_mult(d_image_complex, d_response_complex, out=d_image_complex)\n",
    "\n",
    "    # GPU inverse FFT\n",
    "    cufft.ifft_inplace(d_image_complex)\n",
    "\n",
    "    # explicit GPU->CPU memory transfer\n",
    "    cvimage_gpu = d_image_complex.copy_to_host().real\n",
    "    return cvimage_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the `gpu_mult` gpu ufunc is necessary to keep the memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvimage_gpu = gpu_fftconvolve(image)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(cvimage_gpu, cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing all Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('scipy')\n",
    "%timeit fftconvolve(image, laplacian, mode='same')\n",
    "print('\\nnaive')\n",
    "%timeit naive_fftconvolve(image)\n",
    "print('\\nmkl')\n",
    "%timeit mkl_fftconvolve(image)\n",
    "print('\\ngpu')\n",
    "%timeit gpu_fftconvolve(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using VML to intrinsics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intel's Vector Math Library (VML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VML math functions leverages SIMD instructions for higher throughput.  Use vml ufuncs inplace of numpy ufuncs for simple performance gain when lower precision result is acceptable.\n",
    "\n",
    "See https://docs.continuum.io/accelerate/mkl_ufuncs for a full list of supported functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from accelerate.mkl import vmlufuncs\n",
    "vml = vmlufuncs.ufuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.random.random(10**6).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.allclose(np.sin(arr) * np.cos(arr), \n",
    "            vml.sin(arr) * vml.cos(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit np.sin(arr) * np.cos(arr)\n",
    "%timeit vml.sin(arr) * vml.cos(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "from accelerate.cuda.blas import Blas\n",
    "\n",
    "M = 2000\n",
    "N = 5000\n",
    "P = 3000\n",
    "Q = 1000\n",
    "\n",
    "# Prepare arrays for input\n",
    "A = np.asfortranarray(np.random.random((M, N)), dtype=np.float32)\n",
    "B = np.asfortranarray(np.random.random((N, P)), dtype=np.float32)\n",
    "C = np.asfortranarray(np.random.random((P, Q)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_result = A.dot(B).dot(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blas = Blas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GPU version keeps the intermediate matrices on the GPU.\n",
    "\n",
    "The `blas.gemm` is a binding to cuBLAS GEMM.\n",
    "\n",
    "\n",
    "$ C = \\alpha \\space op(A) \\space  op(B) + \\beta C $\n",
    "\n",
    "\n",
    "Its arguments are:\n",
    "\n",
    "```gemm(transa, transb, m, n, k, alpha, A, B, beta, C)```\n",
    "\n",
    "* transa, transb: str ['N', 'T', 'C']\n",
    "\n",
    "    Indicate an operation on the input matrices: A and B, respectively.\n",
    "\n",
    "    * N: no op\n",
    "    * T: transpose\n",
    "    * C: conjugate transpose\n",
    "    \n",
    "* m, n: int\n",
    "\n",
    "    Shape of output matric\n",
    "    \n",
    "* k: int\n",
    "\n",
    "    The length of the common dimension of A and B\n",
    "    \n",
    "* alpha, beta: float\n",
    "\n",
    "    The value to multiply to A and C, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gpu_compute(A, B, C):\n",
    "    dA = cuda.to_device(A)\n",
    "    dB = cuda.to_device(B)\n",
    "    dC = cuda.to_device(C)\n",
    "    dTmp = cuda.device_array(shape=(M, P), dtype=np.float32, order='F')\n",
    "    dOut = cuda.device_array(shape=(M, Q), dtype=np.float32, order='F')\n",
    "    blas.gemm('N', 'N', M, P, N, 1, dA, dB, 0, dTmp)\n",
    "    blas.gemm('N', 'N', M, Q, P, 1, dTmp, dC, 0, dOut)\n",
    "    return dOut.copy_to_host()\n",
    "    \n",
    "gpu_result = gpu_compute(A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.allclose(cpu_result, gpu_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit A.dot(B).dot(C)\n",
    "%timeit gpu_compute(A, B, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for convolution filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the file `src/fftconvolve.py` for a slightly different coding style and a stand-alone script.  Run this from the command line and look at timings and results that are output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load src/fftconvolve.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br>\n",
    "*Copyright Continuum 2012-2016 All Rights Reserved.*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:iqt]",
   "language": "python",
   "name": "conda-env-iqt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
