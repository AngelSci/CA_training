{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/anaconda-logo.png' align='left' style=\"padding:10px\">\n",
    "<br>\n",
    "*Copyright Continuum 2012-2016 All Rights Reserved.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerate FFT Convolution with Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Distributed GPU FFT convolution (with Dask Distributed)](#Distributed-GPU-FFT-convolution-%28with-Dask-Distributed%29)\n",
    "\t* [GPU FFT Convolvution Code](#GPU-FFT-Convolvution-Code)\n",
    "* [Using ``dask.distributed``](#Using-dask.distributed)\n",
    "\t* [Apply dask.distributed](#Apply-dask.distributed)\n",
    "\t* [Things to Try](#Things-to-Try)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed GPU FFT convolution (with Dask Distributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup:\n",
    "\n",
    "launch dask distributed scheduler\n",
    "\n",
    "```bash\n",
    "$ dscheduler\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "launch dask workers\n",
    "\n",
    "```bash\n",
    "$ dworker <dscheduler_address>:8786\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!dworker --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU FFT Convolvution Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code are the same from earlier lesson on FFT convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.misc import imresize\n",
    "from scipy.ndimage import imread\n",
    "import skimage.data\n",
    "from skimage.color import rgb2gray\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from numba import cuda, vectorize\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build 5x5 laplacian filter\n",
    "laplacian_pts = '''\n",
    "-4 -1 0 -1 -4\n",
    "-1  2 3  2 -1\n",
    " 0  3 4  3  0\n",
    "-1  2 3  2 -1\n",
    "-4 -1 0 -1 -4\n",
    "'''.split()\n",
    "\n",
    "laplacian = np.array(laplacian_pts, dtype=np.float32).reshape(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import accelerate.cuda.fft as cufft\n",
    "\n",
    "@vectorize(['complex64(complex64, complex64)'], target='cuda')\n",
    "def gpu_mult(a, b):\n",
    "    # a GPU ufunc to compute the elementwise product \n",
    "    return a * b\n",
    "\n",
    "def gpu_fftconvolve(image):\n",
    "    image_complex = image.astype(np.complex64)\n",
    "    response_complex = np.zeros_like(image_complex)\n",
    "    response_complex[:5, :5] = laplacian.astype(np.complex64)\n",
    "    \n",
    "    # explicit CPU->GPU memory transfer\n",
    "    d_image_complex = cuda.to_device(image_complex)\n",
    "    d_response_complex = cuda.to_device(response_complex)\n",
    "\n",
    "    # GPU forward FFT\n",
    "    cufft.fft_inplace(d_image_complex)\n",
    "    cufft.fft_inplace(d_response_complex)\n",
    "\n",
    "    # GPU ufunc\n",
    "    gpu_mult(d_image_complex, d_response_complex, out=d_image_complex)\n",
    "\n",
    "    # GPU inverse FFT\n",
    "    cufft.ifft_inplace(d_image_complex)\n",
    "\n",
    "    # explicit GPU->CPU memory transfer\n",
    "    cvimage_gpu = d_image_complex.copy_to_host().real\n",
    "    return cvimage_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ``dask.distributed``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_image(size):\n",
    "    return skimage.data.binary_blobs(length=size).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = generate_image(512)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(im, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our GPU FFT convolve function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = gpu_fftconvolve(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(out, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply dask.distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the scheduler.\n",
    "This follows the same pattern as [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Executor\n",
    "e = Executor('127.0.0.1:8786')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 10 random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = [generate_image(size=512) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter our images to all workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "future_images = e.scatter(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply our GPU FFT convolution function on the loaded images.\n",
    "\n",
    "The function references GPU ufuncs and cuFFT functions.  The jit-compiled GPU ufuncs can be seralized and transfer to the worker node, where it will be deserialized and finalized to machine code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "future_convolved = e.map(gpu_fftconvolve, future_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `.gather` method to get the result of the convolution.  This will not return futures.  The result is a list of arrays of our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convolved = e.gather(future_convolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(convolved[0], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(convolved[1], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to Try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using `dask.distributed`, multi-node and multi-GPU usage becomes a separated problem of worker configuration.  User can launch many instances of `dworker` from different machines and connect to the `dscheduler` process.  For the above example, it is necessary to change how the image data is accessed.  Perhaps, using a distributed filesystem is the simplest way to ensure that all worker process can access the images. \n",
    "\n",
    "To use multiple GPUs, launch multiple `dworker` processes on each machine.  It is advised to reduce the number of threads per worker (the default is to launch as many threads as cpu-cores) to prevent oversubscription.  To designate the GPU for each worker, use environment variable `CUDA_VISIBLE_DEVICES`.  This environment variable is provided by Nvidia driver and it is visible by all CUDA process in the same environment.\n",
    "\n",
    "For example:\n",
    "\n",
    "```bash\n",
    "$ CUDA_VISIBLE_DEVICES=0 dworker --nthreads=2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will launch a `dworker`, with 2 threads, that will see GPU-0 only in the system.\n",
    "\n",
    "To get a list of available devices, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "cuda.detect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Copyright Continuum 2012-2016 All Rights Reserved.*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:iqt]",
   "language": "python",
   "name": "conda-env-iqt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
