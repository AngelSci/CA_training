{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/anaconda-logo.png' align='left' style=\"padding:10px\">\n",
    "<br>\n",
    "*Copyright Continuum 2012-2016 All Rights Reserved.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerate FFT Convolution with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Distributed FFT convolution (with PySpark)](#Distributed-FFT-convolution-%28with-PySpark%29)\n",
    "\t* [GPU FFT Convolvution Code](#GPU-FFT-Convolvution-Code)\n",
    "* [Using PySpark](#Using-PySpark)\n",
    "\t* [Apply PySpark](#Apply-PySpark)\n",
    "\t\t* [Note on multiGPU usage](#Note-on-multiGPU-usage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed FFT convolution (with PySpark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup PySpark in Standalone mode**\n",
    "\n",
    "Start master node:\n",
    "\n",
    "```bash\n",
    "start-master.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start workers:\n",
    "\n",
    "```bash\n",
    "export PYTHONHASHSEED=0   # for python 3 to work\n",
    "start-slave.sh spark://hostname:7077   # find hostname from the log of master\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start notebook:\n",
    "\n",
    "```bash\n",
    "export PYSPARK_PYTHON=`which ipython`\n",
    "export IPYTHON_OPTS=\"notebook --no-browser --ip=<outgoing ip>\" \n",
    "pyspark --master=spark://hostname:7077\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU FFT Convolvution Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code are the same from earlier lesson on FFT convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.misc import imresize\n",
    "import skimage.data\n",
    "from skimage.color import rgb2gray\n",
    "from matplotlib import pyplot as plt\n",
    "from numba import cuda, vectorize\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build 5x5 laplacian filter\n",
    "laplacian_pts = '''\n",
    "-4 -1 0 -1 -4\n",
    "-1  2 3  2 -1\n",
    " 0  3 4  3  0\n",
    "-1  2 3  2 -1\n",
    "-4 -1 0 -1 -4\n",
    "'''.split()\n",
    "\n",
    "laplacian = np.array(laplacian_pts, dtype=np.float32).reshape(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import accelerate.cuda.fft as cufft\n",
    "\n",
    "\n",
    "@vectorize(['complex64(complex64, complex64)'], target='cuda')\n",
    "def gpu_mult(a, b):\n",
    "    # a GPU ufunc to compute the elementwise product \n",
    "    return a * b\n",
    "\n",
    "def gpu_fftconvolve(image):\n",
    "    image_complex = image.astype(np.complex64)\n",
    "    response_complex = np.zeros_like(image_complex)\n",
    "    response_complex[:5, :5] = laplacian.astype(np.complex64)\n",
    "    \n",
    "    # explicit CPU->GPU memory transfer\n",
    "    d_image_complex = cuda.to_device(image_complex)\n",
    "    d_response_complex = cuda.to_device(response_complex)\n",
    "\n",
    "    # GPU forward FFT\n",
    "    cufft.fft_inplace(d_image_complex)\n",
    "    cufft.fft_inplace(d_response_complex)\n",
    "\n",
    "    # GPU ufunc\n",
    "    gpu_mult(d_image_complex, d_response_complex, out=d_image_complex)\n",
    "\n",
    "    # GPU inverse FFT\n",
    "    cufft.ifft_inplace(d_image_complex)\n",
    "\n",
    "    # explicit GPU->CPU memory transfer\n",
    "    cvimage_gpu = d_image_complex.copy_to_host().real\n",
    "    return cvimage_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_image(size):\n",
    "    return skimage.data.binary_blobs(length=size).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view the sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = generate_image(512)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(im, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our GPU FFT convolve function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = gpu_fftconvolve(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(out, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook environment, the Spark Context is available as `sc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = [generate_image(size=512) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send our data to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd_images = sc.parallelize(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply our GPU FFT convolution function on the loaded images.\n",
    "\n",
    "The function references GPU ufuncs and cuFFT functions.  The jit-compiled GPU ufuncs can be seralized and transfer to the worker node, where it will be deserialized and finalized to machine code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd_convolved = rdd_images.map(gpu_fftconvolve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, no computation has occurred yet. RDD computes lazily.  By calling collect, we trigger the computation and gather the result back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convolved = rdd_convolved.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(convolved[0], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(convolved[1], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on multiGPU usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the Dask Distributed version, it is possible to assign specific GPU to each worker using the ``CUDA_VISIBLE_DEVICES`` environment variable when launching the workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Copyright Continuum 2012-2016 All Rights Reserved.*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:iqt]",
   "language": "python",
   "name": "conda-env-iqt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
