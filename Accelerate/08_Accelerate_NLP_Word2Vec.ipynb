{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/anaconda-logo.png' align='left' style=\"padding:10px\">\n",
    "<br>\n",
    "*Copyright Continuum 2012-2016 All Rights Reserved.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerate Natural Language Processing: Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Word2Vec is a unsupervised learning model to reconstruct linguistic context of words.\n",
    "* The model is trained with sentences.  \n",
    "* The model produces a vector for each word.\n",
    "* Elementary arithmetic operations (e.g. addition, subtraction) can be used on these vectors to compute analogies (i.e. \"france\" + \"berlin\" - \"germany\" = \"paris\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Accelerate Natural Language Processing: Word2Vec](#Accelerate-Natural-Language-Processing:-Word2Vec)\n",
    "\t* [Dataset](#Dataset)\n",
    "\t* [Create a Word2Vec model](#Create-a-Word2Vec-model)\n",
    "\t* [Warmup](#Warmup)\n",
    "\t\t* [Quick tests](#Quick-tests)\n",
    "\t\t* [Accuracy test](#Accuracy-test)\n",
    "\t* [Continue learning as a CUDA-enabled Word2Vec model](#Continue-learning-as-a-CUDA-enabled-Word2Vec-model)\n",
    "\t\t* [Train on the GPU](#Train-on-the-GPU)\n",
    "\t\t* [Quick test](#Quick-test)\n",
    "\t* [Downpour Stochastic Gradient Descent](#Downpour-Stochastic-Gradient-Descent)\n",
    "\t\t* [Quick test](#Quick-test)\n",
    "\t\t* [Accuracy test](#Accuracy-test)\n",
    "\t* [Hardware](#Hardware)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gensim.scripts\n",
    "from gensim.models import Word2Vec, CudaWord2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our dataset using the _text8_ dataset.  It is the first 100MB of cleaned text from the english wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the dataset (Linux/macOS)\n",
    "#     !wget -c http://mattmahoney.net/dc/text8.zip\n",
    "#     !unzip -f text8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_url = \"http://mattmahoney.net/dc/text8.zip\"\n",
    "data_file = \"tmp/text8.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a tmp dir\n",
    "import os\n",
    "if not os.path.exists('tmp'):\n",
    "    os.makedirs('tmp')\n",
    "os.listdir(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download data file (30 MB compressed ZIP, ~ 10-20 seconds)\n",
    "# Note: urllib interface differs from python2 to python3\n",
    "\n",
    "import sys\n",
    "python_version = sys.version_info.major\n",
    "\n",
    "if python_version == 2:\n",
    "    import urllib\n",
    "    urllib.urlretrieve(data_url, data_file)\n",
    "elif python_version == 3:\n",
    "    import urllib.request, urllib.parse, urllib.error\n",
    "    urllib.request.urlretrieve(data_url, data_file)\n",
    "\n",
    "os.listdir(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If needed, unzip the data file\n",
    "import zipfile \n",
    "with zipfile.ZipFile(data_file, \"r\") as z:\n",
    "    z.extractall(\"tmp\")\n",
    "os.listdir(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data directly from ZIP archive without extracting to disk\n",
    "import zipfile\n",
    "archive = zipfile.ZipFile(data_file, 'r')\n",
    "text8data = archive.read('text8').decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text8data` is a single line of text.  There is no punctuations.  It is just a string of words where each word is separated by a space.\n",
    "\n",
    "Turn it into a list of words by separating the text at whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text8words = text8data.split()\n",
    "len(text8words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recreate the sentences, we can simplify group every 20 words into a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentlen = 20\n",
    "for i in range(0, len(text8words), sentlen):\n",
    "    sentences.append(text8words[i:i + sentlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in sentences[:5]:\n",
    "    print(' '.join(s), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(size=200, workers=4)  # train 200 dimension vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build vocabulary from all sentences in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with a reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train(sentences[:len(sentences) // 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model.  The answer is probably not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.similarity('cat', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['france', 'berlin'], negative=['germany'])  # expecting 'paris'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['jesus', 'buddhism'], negative=['christianity'])  # expecting 'buddha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.doesnt_match(['man', 'woman', 'boy', 'fork'])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our model with analogies.  This test is used in the original implementation by the original authors at Google.  The `question_words.txt` came from https://code.google.com/archive/p/word2vec/source/default/source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import os.path\n",
    "\n",
    "directory = os.path.dirname(gensim.scripts.__file__)\n",
    "question_file = os.path.join(directory, 'questions_words.txt')\n",
    "\n",
    "def accuracy_test(model):\n",
    "    # Run the accuracy test\n",
    "    results = model.accuracy(question_file)\n",
    "    # Print and format the result\n",
    "    for sect in results:\n",
    "        good = len(sect['correct'])\n",
    "        bad = len(sect['incorrect'])\n",
    "        total = good + bad\n",
    "        if not total:\n",
    "            score = 0\n",
    "        else:\n",
    "            score = 100 * good / total\n",
    "        print('section', sect['section'], '| percent', \"{:.1f}%\".format(score))\n",
    "\n",
    "accuracy_test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue learning as a CUDA-enabled Word2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same CPU model can be loaded as a GPU model by using monkeypatching.  The GPU model, `CudaWord2Vec`, is a subclass of the original `Word2Vec` class.  It overrides the training related methods to perform the training on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CudaWord2Vec()  # to initialize the CUDA Word2Vec system which happens in __init__\n",
    "\n",
    "gpumodel = deepcopy(model)\n",
    "gpumodel.__class__ = CudaWord2Vec  # monkeypatch to a use CUDA (bypasses __init__)\n",
    "\n",
    "assert gpumodel.syn0 is not model.syn0\n",
    "\n",
    "print(type(gpumodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpumodel.similarity('cat', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpumodel.most_similar(positive=['france', 'berlin'], negative=['germany'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpumodel.doesnt_match(['man', 'woman', 'boy', 'fork'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpu_syn0, gpu_syn1 = gpumodel.syn0.copy(), gpumodel.syn1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "gpumodel.train(random.sample(sentences, len(sentences) // 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpumodel.similarity('cat', 'dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute deltas of the layers (vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syn0_delta = gpumodel.syn0 - gpu_syn0\n",
    "syn1_delta = gpumodel.syn1 - gpu_syn1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add the deltas from the gpu model back to the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.syn0 += syn0_delta\n",
    "model.syn1 += syn1_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.similarity('cat', 'dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downpour Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: http://research.google.com/archive/large_deep_networks_nips2012.html\n",
    "\n",
    "\n",
    "We will name our initial model as the \"master\".  For each iteration, copy the master model to the workers and train locally with a random subset of the dataset.  The deltas for each layers are used to update the master model.\n",
    "\n",
    "We will use this technique to train the master model on the CPU and GPU simultaneously.  Since Word2Vec and CudaWord2Vec have similar performance, there is no benefit to use one over the other.  But, using both simultaneously should double our throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(master, sentences, use_gpu=False):\n",
    "    model = deepcopy(master)\n",
    "    if use_gpu:\n",
    "        # monkeypatch the class of the model to use GPU training\n",
    "        model.__class__ = CudaWord2Vec\n",
    "    model.train(sentences)\n",
    "    # compute the detlas\n",
    "    delta_syn0 = model.syn0 - master.syn0\n",
    "    delta_syn1 = model.syn1 - master.syn1\n",
    "    return delta_syn0, delta_syn1\n",
    "\n",
    "def descent(model, deltas, learning_rate):\n",
    "    model.syn0 += deltas[0] * learning_rate\n",
    "    model.syn1 += deltas[1] * learning_rate\n",
    "    \n",
    "def show_norms(deltas):\n",
    "    return 'syn0: {0} | syn1: {1}'.format(np.linalg.norm(deltas[0]), \n",
    "                                          np.linalg.norm(deltas[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "learning_rate = 0.5\n",
    "cat_dog_sims = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as exe:\n",
    "    for _ in range(10):\n",
    "        # Sample the dataset\n",
    "        cpu_sents = random.sample(sentences, len(sentences) // 4)\n",
    "        gpu_sents = random.sample(sentences, len(sentences) // 4)\n",
    "\n",
    "        # Train models in parallel\n",
    "        future_cpu = exe.submit(gradient, model, cpu_sents)\n",
    "        future_gpu = exe.submit(gradient, model, gpu_sents, use_gpu=True)\n",
    "\n",
    "        # Gather data\n",
    "        cpu_deltas = future_cpu.result()\n",
    "        gpu_deltas = future_gpu.result()\n",
    "\n",
    "        # Apply deltas to master model\n",
    "        descent(model, cpu_deltas, learning_rate)\n",
    "        descent(model, gpu_deltas, learning_rate)\n",
    "\n",
    "        print(\"cpu delta norms\", show_norms(cpu_deltas))\n",
    "        print(\"gpu delta norms\", show_norms(gpu_deltas))\n",
    "\n",
    "        sim = model.similarity('cat', 'dog')\n",
    "        print(sim)\n",
    "        cat_dog_sims.append(sim)\n",
    "        \n",
    "        learning_rate *= 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear the internal cache for doing similiarity testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.clear_sims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['france', 'berlin'], negative=['germany'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['jesus', 'buddhism'], negative=['christianity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.doesnt_match(['man', 'woman', 'boy', 'dog'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "accuracy_test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "cuda.detect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "*Copyright Continuum 2012-2016 All Rights Reserved.*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:iqt]",
   "language": "python",
   "name": "conda-env-iqt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
