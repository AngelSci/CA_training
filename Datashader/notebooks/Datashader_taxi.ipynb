{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../../img/anaconda-logo.png' align='left' style=\"padding:10px\">\n",
    "<br>\n",
    "*Copyright Continuum 2012-2016 All Rights Reserved.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datashader GIS Example: Taxi rides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Datashader GIS Example: Taxi rides](#Datashader-GIS-Example:-Taxi-rides)\n",
    "\t* [Set-Up](#Set-Up)\n",
    "* [The Data Set](#The-Data-Set)\n",
    "* [Preparation](#Preparation)\n",
    "* [The Pipeline](#The-Pipeline)\n",
    "\t* [Aggregation and Transform](#Aggregation-and-Transform)\n",
    "\t* [Colormapping Transformations](#Colormapping-Transformations)\n",
    "\t* [Aggregation by Average Distance](#Aggregation-by-Average-Distance)\n",
    "* [Interactive Visualizations](#Interactive-Visualizations)\n",
    "\t* [Use a Better Basemap](#Use-a-Better-Basemap)\n",
    "* [Exercise](#Exercise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set used here is NYC taxi rides from April 1, 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taxi = pd.read_csv('data/April1.csv')\n",
    "taxi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taxi.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitude and longitude positions must be transformed to Meters from the prime meridian (*mercator*) units for mapping overlays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyproj import Proj, transform\n",
    "inProj = Proj(init='epsg:4326')\n",
    "outProj = Proj(init='epsg:3857') \n",
    "\n",
    "# \"epsg:4326\" is a web code for a coordinate reference frame\n",
    "# the coordinate space \"epsg:4326\" (WGS84) is in lat/lon\n",
    "#    http://spatialreference.org/ref/epsg/wgs-84/\n",
    "# the coordinate space \"epsg:3857\" (Web Mercator) is measure in meters\n",
    "# WebMercator says the Earth is a square, and aquares are easy to tile\n",
    "\n",
    "\n",
    "# Now let's apply the projection from one coordinate space for another\n",
    "taxi['pickup_x'], taxi['pickup_y'] = \\\n",
    "  transform(inProj, outProj, taxi['pickup_longitude'].values, taxi['pickup_latitude'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Alternative, if you have successfully run `master_download.py` and have the full data set for NYC taxis\n",
    "# taxi = pd.read_csv('../../data/Datashader/nyc_taxi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "from datashader import transfer_functions as tf\n",
    "from datashader.colors import Greys9\n",
    "Greys9_r = list(reversed(Greys9))[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation and Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate the data by number of rides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_range=(-8250000,-8210000)\n",
    "y_range=(4965000,4990000)\n",
    "\n",
    "cvs = ds.Canvas(plot_width=800, plot_height=500, x_range=x_range, y_range=y_range)\n",
    "agg = cvs.points(taxi, 'pickup_x', 'pickup_y')\n",
    "tf.shade(agg, cmap=Greys9_r, how='eq_hist')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colormapping Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color mapping: blue indicates higher density of rides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datashader.colors import inferno\n",
    "\n",
    "x_range=(-8250000,-8210000)\n",
    "y_range=(4965000,4990000)\n",
    "\n",
    "cvs = ds.Canvas(plot_width=800, plot_height=500, x_range=x_range, y_range=y_range)\n",
    "agg = cvs.points(taxi, 'pickup_x', 'pickup_y')\n",
    "tf.shade(agg, cmap=reversed(inferno), how='eq_hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation by Average Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate by average distance.\n",
    "\n",
    "Rides from the airport are longer than most others.\n",
    "\n",
    "Once you're in the city why leave?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_range=(-8250000,-8210000)\n",
    "y_range=(4965000,4990000)\n",
    "\n",
    "cvs = ds.Canvas(plot_width=800, plot_height=500, x_range=x_range, y_range=y_range)\n",
    "agg = cvs.points(taxi, 'pickup_x', 'pickup_y', ds.mean('trip_distance'))\n",
    "tf.shade(agg, cmap=reversed(inferno), how='eq_hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "<img src='img/topics/Advanced-Concept.png' align='left' style='padding:10x'>\n",
    "<br>\n",
    "<big><big>\n",
    "Combine Datashader and Bokeh for interative Big Data visualizations.\n",
    "</big></big>\n",
    "<br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new tool used here will be `Dynspread`, which allows the points to expand as plot is zoomed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_img(x_range, y_range, w, h):\n",
    "    cvs = ds.Canvas(plot_width=w, plot_height=h, x_range=x_range, y_range=y_range)\n",
    "    agg = cvs.points(taxi, 'pickup_x', 'pickup_y')\n",
    "    img = tf.shade(agg, cmap=inferno, how='eq_hist')\n",
    "    return tf.dynspread(img, threshold=0.5, max_px=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch how the the plot changes as you zoom in or out.\n",
    "\n",
    "Looking at the `make_img` function above why do you think the colors change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bokeh\n",
    "bokeh.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!conda install bokeh -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.tile_providers import STAMEN_TERRAIN\n",
    "from datashader.bokeh_ext import InteractiveImage\n",
    "\n",
    "ranges = {\n",
    "    'x_range':(-8236013,-8234013),\n",
    "    'y_range':(4971883,4981883)\n",
    "}\n",
    "\n",
    "p = figure(background_fill_color=\"black\",responsive=True, plot_width=900,\n",
    "          **ranges)\n",
    "p.axis.visible = False\n",
    "p.grid.visible = False   # bokeh 0.12.1\n",
    "#p.grid.grid_line_alpha = 0 # bokeh 0.12.0\n",
    "\n",
    "\n",
    "p.add_tile(STAMEN_TERRAIN)\n",
    "\n",
    "InteractiveImage(p, make_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a Better Basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *\"Your basemap should provide context, but not distract nor hide your data.\" -- Master Collins*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_plot(tools='pan,wheel_zoom,reset',plot_width=900, plot_height=600, x_range=None, y_range=None, **plot_args):\n",
    "    p = Figure(tools=tools, plot_width=plot_width, plot_height=plot_height,\n",
    "        x_range=x_range, y_range=y_range, outline_line_color=None,\n",
    "        min_border=0, min_border_left=0, min_border_right=0,\n",
    "        min_border_top=0, min_border_bottom=0, **plot_args)\n",
    "    \n",
    "    p.axis.visible = False\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.add_tile(STAMEN_TONER, alpha=.5)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.tile_providers import STAMEN_TONER ####### chnged this too ######\n",
    "from datashader.bokeh_ext import InteractiveImage\n",
    "\n",
    "ranges = {\n",
    "    'x_range':(-8236013,-8234013),\n",
    "    'y_range':(4971883,4981883)\n",
    "}\n",
    "\n",
    "p = figure(background_fill_color=\"black\",responsive=True, plot_width=900,\n",
    "          **ranges)\n",
    "p.axis.visible = False\n",
    "p.grid.visible = False   # bokeh 0.12.1\n",
    "#p.grid.grid_line_alpha = 0 # bokeh 0.12.0\n",
    "\n",
    "\n",
    "p.add_tile(STAMEN_TONER, alpha=.5)  ####### Changed this line ######\n",
    "\n",
    "InteractiveImage(p, make_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/topics/Exercise.png' align='left' style='padding:10px'>\n",
    "<br>\n",
    "<a href='./Datashader_ex_taxi.ipynb' class='btn btn-primary btn-lg'>Taxi Data</a>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "continuum": {
   "depends": [],
   "requires": [
    "data/April1.csv"
   ],
   "tag": "shade_taxi"
  },
  "kernelspec": {
   "display_name": "Python [conda env:iqt]",
   "language": "python",
   "name": "conda-env-iqt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
