{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logo.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/title.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/py3k.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Learning Objectives](#Learning-Objectives)\n",
    "* [Pandas: Tidy Data](#Pandas:-Tidy-Data)\n",
    "\t* [Set-Up](#Set-Up)\n",
    "* [Overview](#Overview)\n",
    "* [Demonstration](#Demonstration)\n",
    "\t* [Data Load](#Data-Load)\n",
    "\t* [Data Read](#Data-Read)\n",
    "\t* [Data Cleanup](#Data-Cleanup)\n",
    "* [Question: Days of Rest](#Question:-Days-of-Rest)\n",
    "\t* [Data Organization](#Data-Organization)\n",
    "\t* [Translate Question to Operation](#Translate-Question-to-Operation)\n",
    "* [Question: Home Team Advantage](#Question:-Home-Team-Advantage)\n",
    "\t* [Question: Team Strength](#Question:-Team-Strength)\n",
    "\t\t* [Mini Project: Home Court Advantage?](#Mini-Project:-Home-Court-Advantage?)\n",
    "\t\t* [Step 1. Calculate Win %](#Step-1.-Calculate-Win-%)\n",
    "\t\t* [Step 2: Find the win percent for each team](#Step-2:-Find-the-win-percent-for-each-team)\n",
    "* [Merging](#Merging)\n",
    "* [Pivoting](#Pivoting)\n",
    "\t* [Summarizing Pivot](#Summarizing-Pivot)\n",
    "\t* [Transform Pivot](#Transform-Pivot)\n",
    "* [Concat](#Concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this notebook, the learner will be able to:\n",
    "* Use pandas to tidy up data\n",
    "* Limit file reads to just the columns of data needed\n",
    "* Reorganize data to suite the question at hand\n",
    "* Translate a data question into a data operation\n",
    "* Perform SQL-like queries on a pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas: Tidy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 6\n",
    "pd.options.display.max_columns = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structuring datasets to facilitate analysis [(Wickham 2014)](http://www.jstatsoft.org/v59/i10/paper)\n",
    "\n",
    "If there's one maxim I can impart it's that your tools shouldn't get in the way of your analysis. Your problem is already difficult enough, don't let the data or your tools make it any harder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a tidy dataset...\n",
    "\n",
    "1. Each variable forms a column\n",
    "2. Each observation forms a row\n",
    "3. Each type of observational unit forms a table\n",
    "\n",
    "We'll cover a few methods that help you get there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some data from the web and save it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url    = \"http://www.basketball-reference.com/leagues/NBA_2015_games.html\"\n",
    "tables = pd.read_html(url)\n",
    "games  = tables[0]\n",
    "games.to_csv('tmp/games.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the raw data coming in. We need to clean it up a bit before reshaping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the data file before trying to read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -n 5 tmp/games.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a list of the column names we want to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names = ['date1', 'time1', '_', 'away_team', 'away_points', \n",
    "                'home_team', 'home_points', 'n_ot', 'notes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in all of the columns, but rename then according the the passed *names*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games = pd.read_csv('tmp/games.csv', names=column_names, header=None, skiprows=2)\n",
    "games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the``date1`` and the ``time1`` columns in concert form the date with which we want to work.\n",
    "\n",
    "Let's convert these to a new column ``date`` that is a dtype of ``datetime64[ns]``. This is the standard for datetime storage in pandas. We are going to string combine these; this is the ``+`` operator. Then using ``pd.to_datetime`` to do the conversion. We will mark any non-convertible strings with ``NaT``, the standard missing value indicator for ``datetimelikes``. (This is the ``errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games = games.assign(date=lambda x: \n",
    "                     pd.to_datetime(x['date1'] + ' ' + x['time1'], errors='coerce'))\n",
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the old columns we now no longer need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games = games.drop(['_', 'date1', 'time1', 'notes', 'n_ot'], axis='columns')\n",
    "games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a ``.set_index`` on a frame to take a coumn and make it the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we want to et the Index to be the new ``date`` column values AND the current index.\n",
    "\n",
    "by passing ``append=True``, we will form a ``MultiIndex`` of the existing ``Index`` as the first ``level`` and the ``date`` column as the second ``level``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games = games.set_index('date', append=True)\n",
    "games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find having names on ``Index`` levels to be convenient, let's set them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games.index.names = ['game_id', 'date']\n",
    "games       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: Days of Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether or not your dataset is tidy depends on your question. \n",
    "\n",
    "> **How many days of rest did each team get between each game?**\n",
    "\n",
    "Given our question, what is an observation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is `games` a tidy dataset, given our question? No, we have multiple observations (teams) per row. We'll use `pd.melt` to fix that.\n",
    "\n",
    "This is an operation that takes ``wide`` data and makes it ``long``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tidy = pd.melt(games.reset_index(),\n",
    "               id_vars=['game_id', 'date'], \n",
    "               var_name='which',\n",
    "               value_vars=['away_team', 'home_team'],\n",
    "               value_name='team')\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we took our data and ``un-pivotted`` it, by duplicating the ``game_id`` and ``date`` columns. So we have 2472 rows now, from 1236 before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tidy[tidy.game_id==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reverse this above ``wide`` to ``long`` operation, we can ``pivot`` to go from ``long`` to ``wide``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(tidy\n",
    "     .pivot(index='game_id',columns='which')\n",
    "     .reset_index()\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now the original 1236 rows. Its not *exactly* the same in that we created a ``MultiIndex`` on the columns. But it should be clear that this is the same structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Question to Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have tidy data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows provide a singular observation. These are unique observations if you consider the tuple:\n",
    "\n",
    "```python\n",
    "(game_id, date, which)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our ``variable`` is the ``team`` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that translation from question to operation is direct:\n",
    "\n",
    "For each team... get number of days between games\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tidy.groupby('team')['date'].diff().dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is grouped for all teams so the calculation is done *per-team*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here is a single team results\n",
    "\n",
    "tidy.groupby('team').get_group('Los Angeles Lakers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is effectively rounding down from the number of days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tidy.groupby('team').get_group('Los Angeles Lakers')['date'].diff().dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add on the ``rest`` column to indicate how many days of reset we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tidy['rest'] = (tidy\n",
    "                    .sort_values('date')\n",
    "                    .groupby('team')\n",
    "                    .date.diff()\n",
    "                    .dt\n",
    "                    .days\n",
    ")\n",
    "tidy.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a fancy plot, using the ``seaborn`` library. This is a nice ways of taking a set of data (our team), and displaying data about it (in the Categories ``which``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(tidy.dropna()\n",
    "     .pipe(sns.FacetGrid, col='team', col_wrap=9, hue='team')\n",
    "     .map(sns.barplot, \"which\", \"rest\")\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoosh, that is an interesting plot. But what are we doing?\n",
    "\n",
    "Let's select out a single team and examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(tidy\n",
    "     .dropna()\n",
    "     .query('team == \"Los Angeles Lakers\"')\n",
    "     .pipe(sns.FacetGrid, col='team', hue='team')\n",
    "     .map(sns.barplot, \"which\", \"rest\")\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are effectively doing a ``mean`` on the key variable ``rest``\n",
    "\n",
    "In addition we are illustrating using ``.query`` to perform an operation similar to ``.loc[..]``, that selects out data based on the passed criteria. ``.query`` accepts a string expression where you can use columns (``team`` in this case easily). This is analagous to a ``select`` in SQL-speak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = (tidy\n",
    "        .dropna()\n",
    "        .query('team == \"Los Angeles Lakers\"')\n",
    "        .groupby('which')\n",
    "     )\n",
    "g.rest.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: Home Team Advantage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now discuss some more reshaping operations. We have already seen: \n",
    "\n",
    "- ``.set_index()`` and ``.reset_index()`` to take a column and make it the index (and vice-versa).\n",
    "- ``pd.melt()`` and ``.pivot()`` to take the uniques of a column and ``unstack`` or ``stack`` them.\n",
    "\n",
    "Now let's meet a related pair of operations, ``.stack`` and ``.unstack``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An \"observation\" depends on the question. Is there a Home team advantage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "home_adv = games.home_points - games.away_points\n",
    "ax = home_adv.plot(kind='hist', bins=80, figsize=(10, 5))\n",
    "ax.set_xlim(-40, 40)\n",
    "ax.vlines(home_adv.mean(), *ax.get_ylim(), color='red', linewidth=3)\n",
    "print('Home win percent:', (home_adv > 0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: Team Strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Project: Home Court Advantage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the effect (in terms of probability to win) of being\n",
    "the home team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Calculate Win %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create an indicator for whether the home team won.\n",
    "Add it as a column called `home_win` in `games`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games['home_win'] = games['home_points'] > games['away_points']\n",
    "games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Find the win percent for each team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teams are split across two columns. It's easiest to calculate the number of wins and number of games as away, and the number of wins and number of games as home. Then combine those two results to get the win percent.\n",
    "\n",
    "This is using the ``.agg()`` function of groupby. You can easily specify different aggregations (the values of the dict) AND name them (the keys of the dict) at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games.home_win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using ``(~x)`` to select the invert of a boolean, IOW, ``False`` -> ``True`` and ``True`` -> ``False``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wins_as_away = games.groupby('away_team').home_win.agg(\n",
    "    {'n_games': 'count', 'n_wins': lambda x: (~x).sum()}\n",
    ")\n",
    "wins_as_home = games.groupby('home_team').home_win.agg(\n",
    "    {'n_games': 'count', 'n_wins': 'sum'}\n",
    ")\n",
    "wins = (wins_as_away + wins_as_home)\n",
    "wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, calculate the win percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strength = wins.n_wins / wins.n_games\n",
    "strength.index.name = 'team'\n",
    "strength.name = 'strength'\n",
    "strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a plot of the strength, a viz of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strength.sort_values().plot.barh(figsize=(4,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging is one way of combing data from two different DataFrames into one. They don't have to be the same shape. This is very similar to a ``join`` operation in ``SQL``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring the `strength` values in for each team, for each game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SQL people\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM games NATURAL JOIN strength\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need to get the names worked out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(strength\n",
    "         .head()\n",
    "         .reset_index()\n",
    "         .rename(columns=lambda x: 'away_' + x)\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do a sequence of merges; here are ``.pipe``-ing to ourselves to make the expression a tiny-bit more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(pd.merge(games.reset_index(), \n",
    "          strength.reset_index().add_prefix('away_'))\n",
    "   .pipe(pd.merge, \n",
    "         strength.reset_index().add_prefix('home_'))\n",
    "   .set_index(['game_id', 'date'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seemed a bit complicated, so\n",
    "\n",
    "For python people.\n",
    "\n",
    "we can use the ``.map()`` function which take a dictionary-like (a dict or a Series), where it ``maps`` the keys onto the index of the target Series and replaces the target values with the values from the mappee.\n",
    "\n",
    "This is conceptually what a ``merge`` does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games = games.assign(away_strength=games.away_team.map(strength),\n",
    "                     home_strength=games.home_team.map(strength))\n",
    "games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivoting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's revisit pivot-ing.\n",
    "\n",
    "Pivot takes the uniques in a column and forms columns out of them. There is not data summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(tidy\n",
    "     .pivot(index='game_id',columns='which')\n",
    "     .reset_index()\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing Pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, sometimes you DO want to summarize data; ``pd.pivot_table`` will by default aggretate with ``.mean()``. This is a ``summarizing`` pivot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(tidy,\n",
    "                     values='rest',\n",
    "                     index='which',\n",
    "                     columns='team',\n",
    "                     aggfunc='mean'\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to a groupby by the aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(tidy.groupby(['team','which'])\n",
    "     .rest\n",
    "     .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "followed by an unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(tidy.groupby(['team','which'])\n",
    "     .rest\n",
    "     .mean()\n",
    "     .unstack('team')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(pd.pivot_table(tidy,\n",
    "                     values='rest',\n",
    "                     index=['game_id','date'],\n",
    "                     columns='which',\n",
    "                     aggfunc='mean')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "un = (pd.pivot_table(tidy,\n",
    "                     values='rest',\n",
    "                     index=['game_id','date'],\n",
    "                     columns='which',\n",
    "                     aggfunc='mean')\n",
    "        .rename(columns={'away_team': 'away_rest', 'home_team': 'home_rest'})\n",
    ")\n",
    "un.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "un.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometime we sould like to ``glue`` pandas objects together, without the need for a merge. These objects will be aligned, so they don't have to be the same shape'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = pd.concat([games, un], axis=1).reset_index('date')\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/copyright.png'>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda_training]",
   "language": "python",
   "name": "conda-env-anaconda_training-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
