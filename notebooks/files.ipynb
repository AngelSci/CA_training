{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logo.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/title.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/py3k.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Learning Objectives:](#Learning-Objectives:)\n",
    "* [Input and output](#Input-and-output)\n",
    "\t* [The `input` function](#The-input-function)\n",
    "\t* [The `print` function](#The-print-function)\n",
    "\t* [`stdin`, `stdout`, and `stderr`](#stdin,-stdout,-and-stderr)\n",
    "\t* [Basic file I/O](#Basic-file-I/O)\n",
    "\t* [Delimited data files](#Delimited-data-files)\n",
    "* [Reading from a URL](#Reading-from-a-URL)\n",
    "* [Pickling objects](#Pickling-objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completion of this module, learners should be able to:\n",
    "\n",
    "* use & explain common Python idioms for working with text files\n",
    "* retrieve information from websites\n",
    "* pickle and load Python objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic file I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generic way to work with files is by *opening* them (either for reading or writing). The important Python keyword for opening files is `open`. We'll create a string to write to a file for illustrative purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's first create a string to write to a file\n",
    "lumberjack = \"\"\"He's a lumberjack and he's OK. He sleeps all night and he work all day.\n",
    "I cut down trees, I eat my lunch,\n",
    "I go to the lava-try.\n",
    "On Wednesdays I go shoppin'\n",
    "And have buttered scones for tea. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, let's write a file to disk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The value returned by the function `open` is a *stream object* that we'll usually refer to as an *open file* or *file handle*.\n",
    "* The call to the function `open()` accepts a string with a path to a filename as a first argument. The path can contain  forward slash characters (i.e., `/`) to separate directories and files, as long as the path is valid.  Backslash characters (i.e. `\\`) are permitted on Windows systems also.\n",
    "* The option keyword argument `mode='w'` means *writeable*. There are other alternatives.  \n",
    "\n",
    "|Character|Meaning|\n",
    "|:-:|:-|\n",
    "|`r`| open for reading (default) |\n",
    "|`w`| open for writing, truncating the file first |\n",
    "|`x`| create a new file and open it for writing |\n",
    "|`a`| open for writing, appending to the end of the file if it exists|\n",
    "|`b`| binary mode |\n",
    "|`t`| text mode (default)|\n",
    "|`+`| open a disk file for updating (reading and writing)  \n",
    "\n",
    "* The invocation `outfile.write(long_string)` writes the text string as is (including line breaks) to disk.\n",
    "* More invocations of the form `outfile.write(`*`string`*`)` would append more strings after the text currently in the file.\n",
    "* The method `outfile.writelines(sequence_of_strings)` will write multiple strings at once.\n",
    "* The invocation `outfile.close()` closes the file that was previously opened for writing.\n",
    "* Stream objects have several useful methods and attributes we can investigate using `help`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is generally a good idea to close an open file (stream object) when it is no longer needed using the `close()` method. The Python standard does not guarantee that open files will be closed upon exit from the program. The CPython implementation does, in practice, close any unclosed files, but that is not guaranteed in all Python implementations (e.g., in IronPython or in Jython).  Of greater concern, however, is that a file might remain open throughout a program run, and attempts to read or write from it later might not behave as expected. It is safest to match any `file=open(...)` invocation with a matching `file.close()` invocation.\n",
    "\n",
    "Actually, there is an even safer idiom for file-handling that uses the idiom\n",
    "\n",
    "```python\n",
    "with open(filename) as file:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to enclose a block that uses `file`. At the end of the `with` block, the file is closed automatically. It is good practice to use the `with` statement when opening file objects because it is guaranteed to close the file *no matter how the nested block exits*. Even if an exception occurs before the end of the block, the file will be closed prior to passing the exception up to an outer exception handler (the `with` block is also shorter than the corresponding `try-except-finally` block). The `with` statement also closes the file even if the nested block contains `return`, `continue`, or `break` statements. For other use cases, [The Python \"with\" Statement by Example](http://preshing.com/20110920/the-python-with-statement-by-example/) contains an interesting discussion of using `with` as a context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The `readline` method reads lines from a file one at a time. When there are no more lines to read, the `readline` method returns an empty string.\n",
    "* The `readlines` method also reads the file line by line but it reads the whole file at once. Notice that the linefeed characters are preserved in each element of the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* At the end of the `with` block, the file is closed without having to execute `infile.close()`.\n",
    "* The stream method `read()` reads data from the stream object `infile` into a string `lines`.\n",
    "* By default, the data from the stream is treated as plain text, but this can be overridden.\n",
    "* Attempting to read a non-existent file produces an error.\n",
    "* Attempting to write/append to a non-existent file creates an empty file.\n",
    "* Attempting to read or write to a stream that has been close produces an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Opening a non-existent file for reading: FileNotFoundError\n",
    "with open('no-such-file') as infile: # Default: mode='r'\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# By contrast, opening a non-existent file for write/append mode *creates* file\n",
    "with open('./tmp/make-the-file', 'a') as newfile:\n",
    "    pass\n",
    "%ls -l tmp/make-the-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# once closed, we cannot write more to outfile.\n",
    "newfile.write(\"More stuff\") # raises a ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more Pythonic way to read data from a text file is to read it line-by-line using a `for` loop. Just as with various data collections, a stream is an *iterable* in Python; hence, it can be looped over. This is probably a wiser choice when dealing with arbitrarily large files that can in principle fill the available memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It is often more idiomatic to read by lines in a loop\n",
    "with open('data/lumberjack.txt') as infile:\n",
    "    for line in infile:\n",
    "        print(line.upper(), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use comprehensions to open, read and manipulate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a comprehension we can open the file and find all of the 's' words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading by chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can read a file in fixed-size chunks (not just line by line)\n",
    "from random import random\n",
    "\n",
    "CHUNK_SIZE = 4    # Specify block-size in bytes\n",
    "\n",
    "with open('data/lumberjack.txt') as infile:\n",
    "    while True:\n",
    "        chunk = infile.read(CHUNK_SIZE)\n",
    "        if not chunk:\n",
    "            break\n",
    "            \n",
    "        # randomly choose to make upper case every 4 bytes    \n",
    "        if random() < 0.5:\n",
    "            print(chunk.upper(), end='')\n",
    "        else:\n",
    "            print(chunk.lower(), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delimited data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often, text files represent tabular data using a *delimiter* to separate columns. We illustrate a few examples of writing and reading CSV (*comma-separated-values*) files or similarly TSV (*tab-separated-values*) or other delimiters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a multiplication table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`print()` accepts the `file=` keyword argument to print directly to a file.\n",
    "\n",
    "Let's do this without generating all of the data in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here is a \"hand-crafted\" way to write a TSV file of numbers\n",
    "\n",
    "nrows = 10\n",
    "ncols = 4 \n",
    "filename = './tmp/table.tsv'\n",
    "\n",
    "with open(filename,'w') as table:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the table.\n",
    "* read in one line at a time\n",
    "* split the values\n",
    "* what data type did Python assume?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the table into a list-of-lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, rather than developing code for reading and writing to CSV/TSV files, we can use a module from the Python Standard Library (namely `csv`). When confronted with a new data analysis problem, *always* check to see if there is a library. There is a good chance someone else has had a similar problem to solve and has developed a module that will solve the problem for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here, we open a CSV file and create a custom stream using csv.reader.\n",
    "# The csv.reader stream can be iterated over in a for loop that extracts rows\n",
    "# from the CSV file and separates entries into Python lists of strings. We \n",
    "# could do this with str.split(','), but the code has been written for us.\n",
    "import csv\n",
    "with open('./data/AAPL.csv') as csvfile:\n",
    "    stockreader = csv.reader(csvfile)\n",
    "    for row in stockreader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from a URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python Standard library includes a module called `urllib`. The `urlopen` function is capable of reading many different protocols including `file:`, `ftp:` and `imap:`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url='http://www.wunderground.com/history/airport/KAGC/2016/1/6/DailyHistory.html?req_city=Pittsburgh&req_state=PA&req_statename=Pennsylvania&reqdb.zip=15206&reqdb.magic=1&reqdb.wmo=99999&format=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`urlopen` creates a connection to the website much like `open` created a connection to a file. We can now call `.read` inside the `with` context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python 3 (Note: Python 2 urlopen does not use the with statement as below)\n",
    "with url_conn as u:\n",
    "    contents = u.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(contents.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases there can be quite a lot of additional text processing required before you can work with the data. There are many modules available in Python. For example, [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/bs4/doc/) is great for parsing HTML content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some of it by hand:\n",
    "* strip trailing newline character\n",
    "* replace `<br />` with empty strings\n",
    "* split along `,` per line\n",
    "* remove empty lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the average temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `pickle` is a binary dump of a Python object to a file. Here we are opening a new file called `weather.pkl` and declaring it to be binary with `wb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./tmp/weather.pkl', 'wb') as out_file:\n",
    "    pickle.dump(weather,out_file)\n",
    "%ls -l tmp/weather.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same context manager idiom we can load the pickle directly into a new object. Reading foreign pickle files can be dangerous as malicious code stored in the pickle could be run on `load`. It is best to keep pickle files for local use only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./tmp/weather.pkl','rb') as in_file:\n",
    "    new_weather = pickle.load(in_file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in new_weather:\n",
    "    print(line[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/copyright.png'>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda_training]",
   "language": "python",
   "name": "conda-env-anaconda_training-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
