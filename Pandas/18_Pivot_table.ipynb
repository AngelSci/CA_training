{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Learning Objectives:](#Learning-Objectives:)\n",
    "* [Sales data](#Sales-data)\n",
    "* [Purchasing patterns](#Purchasing-patterns)\n",
    "\t* [Pivot table](#Pivot-table)\n",
    "\t* [Nested Pivot tables](#Nested-Pivot-tables)\n",
    "\t\t* [Compare to IndexSlice](#Compare-to-IndexSlice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completion of this module, learners should be able to:\n",
    "\n",
    "* Read data from multiple files into a single data frame\n",
    "* Construct pivot tables for complex grouping and aggregation tasks\n",
    "* Use cross section (`.xs`) to make selections from a hierarchical DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Purchasing patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data comes from [Practical Business Python](http://pbpython.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the sales data from 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sample-sales.csv` file contains 1000 purchase entries for a fictitious company. This company sells shirts, shoes and belts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items_sold = pd.read_csv('data/pbpython/sample-sales.csv')\n",
    "items_sold['date'] = pd.to_datetime(items_sold['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items_sold.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items_sold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `include=` keyword argument to `.describe()` allows statistical operations to be performed on no-numeric columns. In this data set we see that there are 718 unique account names and 3 unique categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items_sold.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items_sold['category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous exercise we performed a `groupby` operation followed by an aggregation method and a call to `.unique()` to determine how many unique Account Names bought either belts, shirts or shoes.\n",
    "\n",
    "Using the `items_sold` DataFrame I want the following information in a single table\n",
    "\n",
    "1. Group the data by the three unique *categories*\n",
    "1. For each *category* group the *quantity* by *Account Name* and add the results\n",
    "\n",
    "Doing it only with `groubpy` can be a bit hard as two calls are required and the resulting series objects need to be recombined into a DataFrame with correct column names. There may be more than one way of doing this operation with `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the hard way\n",
    "grp = items_sold.groupby('category')\n",
    "\n",
    "dfs = {i:grp.get_group(i).groupby('Account Name')['quantity'].sum()\n",
    "       for i in grp.groups}\n",
    "\n",
    "pd.DataFrame(dfs).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *pivot table* can be used to create a single DataFrame that performs multiple `groupby`, aggregation and re-indexing operations.\n",
    "\n",
    "The input arguments to `pivot_table` are\n",
    "* `values`: the column over which to aggregate\n",
    "* `index`: the column to be used as the index at the end\n",
    "* `columns`: the column used to group the `values` by\n",
    "* `aggfunc`: the aggregation method to perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = pd.pivot_table(items_sold,\n",
    "               values='quantity', \n",
    "               index='Account Name',\n",
    "               columns='category',\n",
    "               aggfunc=np.sum)\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a single DataFrame I can iterate over the columns `Belt`, `Shirt` and `Shoes` to determine how many customers bought each of the three items.\n",
    "\n",
    "Notice the use of `.notnull()`. This creates a bool array of False where the value is `NaN` and True otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loop over columns\n",
    "for item in categories:\n",
    "    idx = categories[item].notnull()\n",
    "    amount = len(categories.loc[idx,item])\n",
    "    print(\"%d customers bought %s\" % (amount,item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I have all of the data contained in columns I can ask further questions by creating fancy indexing arrays.\n",
    "\n",
    "For example, how many customers bought `Shoes` **and** `Belts`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = categories['Shirt'].notnull() & categories['Shoes'].notnull()\n",
    "shoes_and_belts = categories[idx].shape[0]\n",
    "print(\"%d customers bought shoes and belts\" % shoes_and_belts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many customers bought `Shirts` **but not** `Belts`. The `.isnull()` method is the logical reverse of `.notnull()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = categories['Shirt'].notnull() & categories['Belt'].isnull()\n",
    "shoes_not_belts = categories[idx].shape[0]\n",
    "print(\"%d customers bought shoes and not belts\" % shoes_not_belts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, our favorite customers are those who bought Shirts **and** Belts **and** Shoes are these are the rows that have no `NaN` values so `.dropna()` is the most convenient method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_favorites = categories.dropna(how='any') # how='any' is default\n",
    "our_favorites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Pivot tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four keyword arguments used above, `index`, `values`, `columns` and `aggfunc` can each take a list of values to add more columns or construct hierarchical indexes and columns.\n",
    "\n",
    "For example, the `salesfunnel.xlsx` data set represents sales activities for several `Products` that are sold by the company along with the account name, the sales representative and the sales manager. A hierarchical approach to this data set is \n",
    "\n",
    "* A `Manager` may oversee multiple `Reps`\n",
    "  * A `Rep` will sell each of the `Products`\n",
    "    * A number of different customers are managed by each sales `Rep`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/pbpython/salesfunnel.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a pivot table to build the hierarchical indexing along with performing aggregations on the numeric quantities `Quantity` and `Price`. This gives us a global view of the data set that we can use to determine employee and manager performance.\n",
    "\n",
    "I want to know the total and average quantities of each of the three products sold per sales representative and group them by sales manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df,\n",
    "                       index=[\"Manager\",\"Rep\",\"Product\"],\n",
    "                       values=[\"Price\",\"Quantity\"],\n",
    "                       aggfunc=[np.sum,np.mean])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help with performing selections on MultiIndexes the cross section (`.xs()`) method allows easy selection of a level and a value to select from the whole DataFrame.\n",
    "\n",
    "For instance, we can see all sales data by `Reps` managed by *Fred Anderson*. The cross section method will always **drop** the level that is being selected. It can be disabled with the `drop_level=` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table.xs('Fred Anderson', level='Manager', drop_level=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values from multiple levels can be provided in a container. It is also possible to chain cross section calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table.xs(['Debra Henley','Daniel Hilton']).xs('Quantity', level=1, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross section method is not only less cumbersome, but is generally a bit faster than using the standard MultiIndex slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit table.xs(['Debra Henley','Daniel Hilton']).xs('Quantity', level=1, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "idx = pd.IndexSlice\n",
    "table.loc[idx['Debra Henley', 'Daniel Hilton' , :], idx[:, 'Quantity']]"
   ]
  }
 ],
 "metadata": {
  "continuum": {
   "depends": [
    "pd_intro",
    "pd_groupby"
   ],
   "requires": [
    "data/pbpython/*",
    "data/pbpython/sales-*-2014.xlsx",
    "data/pbpython/sales-jan-2014.xlsx",
    "data/pbpython/salesfunnel.xlsx",
    "data/pbpython/customer-status.xlsx",
    "data/pbpython/sample-sales.csv",
    "data/pbpython/sales-mar-2014.xlsx"
   ],
   "tag": "pd_pivot_table"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
