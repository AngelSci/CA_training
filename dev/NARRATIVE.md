# Course Narrative

* How Does it all Fit Together? 
* What use case motivates each product?
* What problem does each product solve?

## Working with Data, Locally

* Reading Data 
    * IOPro 
* Computing Data
    * Anaconda Accelerate (Numba, NumbaPro)
    * Dask (locally parallel use case) 
* Visualizing Data
    * Bokeh
    * Datashader 

## Working with Data, Distributed

* Visualizing LOTS of data 
    * Bokeh
    * Datasharer 
* Parallel Computing
    * Dask (distributed use case)
* Cluster Computing
    * Anaconda Cluster
    * Be able to distribute jobs to nodes
    * Be able to use Spark 
    * makes it easy to spin up and spin down nodes
    * Be able to distribute jobs to those nodes
    * deploying conda environments to nodes
    * deploying executables and data to nodes
    * can deploy spark to nodes

## Working with Other People

* Environments:
    * Conda and Anaconda
    * conda environments
    * installing packages
    * sharing environment files 
* Team Sharing:
    * Anaconda Enterprise Notebooks
    * All about projects 
    * Like github for analysis projects
    * Analysis projects at the Team Level
    * Projects under development, not deployed
    * Trying to build a model, munge data
    * Projects
        * .ipynb
        * .py
        * .dat
    * Can push from here to Anaconda Repository
        * CLI and GUI methods
        * Access control
        * Workbench App  
* Organizational Sharing:
    * Anaconda Repository
    * Can conda install from a channel
    * Can inspect channels to see work progress of a team
    * Sharing with other teams
    * Can run their code against your alternant data set 
    * Archiving project work
    * Hosting data set in a central location for many to use
    * For Production and Deploy quality 
    * Used to publish and share projects 
    * Push things to Repository from AEN or from workstation


